{"16": [{"idx": 0, "title": "A single hidden layer feedforward network with only one neuron in the hidden layer can approximate any univariate function", "abstract": "The possibility of approximating a continuous function on a compact subset of\nthe real line by a feedforward single hidden layer neural network with a\nsigmoidal activation function has been studied in many papers. Such networks\ncan approximate an arbitrary continuous function provided that an unlimited\nnumber of neurons in a hidden layer is permitted. In this paper, we consider\nconstructive approximation on any finite interval of $\\mathbb{R}$ by neural\nnetworks with only one neuron in the hidden layer. We construct algorithmically\na smooth, sigmoidal, almost monotone activation function $\u03c3$ providing\napproximation to an arbitrary continuous function within any degree of\naccuracy. This algorithm is implemented in a computer program, which computes\nthe value of $\u03c3$ at any reasonable point of the real axis.", "subject": "Neural and Evolutionary Computing (cs.NE)"}, {"idx": 1, "title": "Overview of Full-Dimension MIMO in LTE-Advanced Pro", "abstract": "Multiple-input multiple-output (MIMO) systems with a large number of\nbasestation antennas, often called massive MIMO, have received much attention\nin academia and industry as a means to improve the spectral efficiency, energy\nefficiency, and processing complexity of next generation cellular system.\nMobile communication industry has initiated a feasibility study of massive MIMO\nsystems to meet the increasing demand of future wireless systems. Field trials\nof the proof-of-concept systems have demonstrated the potential gain of the\nFull-Dimension MIMO (FD-MIMO), an official name for the MIMO enhancement in 3rd\ngeneration partnership project (3GPP). 3GPP initiated standardization activity\nfor the seamless integration of this technology into current 4G LTE systems. In\nthis article, we provide an overview of the FD-MIMO system, with emphasis on\nthe discussion and debate conducted on the standardization process of Release\n13. We present key features for FD-MIMO systems, a summary of the major issues\nfor the standardization and practical system design, and performance\nevaluations for typical FD-MIMO scenarios.", "subject": "Information Theory (cs.IT)"}, {"idx": 2, "title": "Event Specific Multimodal Pattern Mining with Image-Caption Pairs", "abstract": "In this paper we describe a novel framework and algorithms for discovering\nimage patch patterns from a large corpus of weakly supervised image-caption\npairs generated from news events. Current pattern mining techniques attempt to\nfind patterns that are representative and discriminative, we stipulate that our\ndiscovered patterns must also be recognizable by humans and preferably with\nmeaningful names. We propose a new multimodal pattern mining approach that\nleverages the descriptive captions often accompanying news images to learn\nsemantically meaningful image patch patterns. The mutltimodal patterns are then\nnamed using words mined from the associated image captions for each pattern. A\nnovel evaluation framework is provided that demonstrates our patterns are 26.2%\nmore semantically meaningful than those discovered by the state of the art\nvision only pipeline, and that we can provide tags for the discovered images\npatches with 54.5% accuracy with no direct supervision. Our methods also\ndiscover named patterns beyond those covered by the existing image datasets\nlike ImageNet. To the best of our knowledge this is the first algorithm\ndeveloped to automatically mine image patch patterns that have strong semantic\nmeaning specific to high-level news events, and then evaluate these patterns\nbased on that criteria.", "subject": "Computer Vision and Pattern Recognition (cs.CV)"}, {"idx": 3, "title": "Selecting Near-Optimal Learners via Incremental Data Allocation", "abstract": "We study a novel machine learning (ML) problem setting of sequentially\nallocating small subsets of training data amongst a large set of classifiers.\nThe goal is to select a classifier that will give near-optimal accuracy when\ntrained on all data, while also minimizing the cost of misallocated samples.\nThis is motivated by large modern datasets and ML toolkits with many\ncombinations of learning algorithms and hyper-parameters. Inspired by the\nprinciple of \"optimism under uncertainty,\" we propose an innovative strategy,\nData Allocation using Upper Bounds (DAUB), which robustly achieves these\nobjectives across a variety of real-world datasets.\n  We further develop substantial theoretical support for DAUB in an idealized\nsetting where the expected accuracy of a classifier trained on $n$ samples can\nbe known exactly. Under these conditions we establish a rigorous sub-linear\nbound on the regret of the approach (in terms of misallocated data), as well as\na rigorous bound on suboptimality of the selected classifier. Our accuracy\nestimates using real-world datasets only entail mild violations of the\ntheoretical scenario, suggesting that the practical behavior of DAUB is likely\nto approach the idealized behavior.", "subject": "Machine Learning (cs.LG)"}, {"idx": 4, "title": "Write a Classifier: Predicting Visual Classifiers from Unstructured Text", "abstract": "People typically learn through exposure to visual concepts associated with\nlinguistic descriptions. For instance, teaching visual object categories to\nchildren is often accompanied by descriptions in text or speech. In a machine\nlearning context, these observations motivates us to ask whether this learning\nprocess could be computationally modeled to learn visual classifiers. More\nspecifically, the main question of this work is how to utilize purely textual\ndescription of visual classes with no training images, to learn explicit visual\nclassifiers for them. We propose and investigate two baseline formulations,\nbased on regression and domain transfer, that predict a linear classifier.\nThen, we propose a new constrained optimization formulation that combines a\nregression function and a knowledge transfer function with additional\nconstraints to predict the parameters of a linear classifier. We also propose a\ngeneric kernelized models where a kernel classifier is predicted in the form\ndefined by the representer theorem. The kernelized models allow defining and\nutilizing any two RKHS (Reproducing Kernel Hilbert Space) kernel functions in\nthe visual space and text space, respectively. We finally propose a kernel\nfunction between unstructured text descriptions that builds on distributional\nsemantics, which shows an advantage in our setting and could be useful for\nother applications. We applied all the studied models to predict visual\nclassifiers on two fine-grained and challenging categorization datasets (CU\nBirds and Flower Datasets), and the results indicate successful predictions of\nour final model over several baselines that we designed.", "subject": "Computer Vision and Pattern Recognition (cs.CV)"}, {"idx": 5, "title": "Computational Pathology: Challenges and Promises for Tissue Analysis", "abstract": "The histological assessment of human tissue has emerged as the key challenge\nfor detection and treatment of cancer. A plethora of different data sources\nranging from tissue microarray data to gene expression, proteomics or\nmetabolomics data provide a detailed overview of the health status of a\npatient. Medical doctors need to assess these information sources and they rely\non data driven automatic analysis tools. Methods for classification, grouping\nand segmentation of heterogeneous data sources as well as regression of noisy\ndependencies and estimation of survival probabilities enter the processing\nworkflow of a pathology diagnosis system at various stages. This paper reports\non state-of-the-art of the design and effectiveness of computational pathology\nworkflows and it discusses future research directions in this emergent field of\nmedical informatics and diagnostic machine learning.", "subject": "Computer Vision and Pattern Recognition (cs.CV)"}, {"idx": 6, "title": "Supporting Multi-hop Device-to-Device Networks Through WiFi Direct Multi-group Networking", "abstract": "With the increasing availability of mobile devices that natively support\nDevice-to-Device (D2D) communication protocols, we are presented with a unique\nopportunity to realize large scale ad hoc wireless networks. Recently, a novel\nD2D protocol named WiFi Direct has been proposed and standardized by the WiFi\nAlliance with the objective of facilitating the interconnection of nearby\ndevices. However, WiFi Direct has been designed following a client-server\nhierarchical architecture, where a single device manages all the communications\nwithin a group of devices. In this paper, we propose and analyze different\nsolutions for supporting the communications between multiple WiFi Direct groups\nusing Android OS devices. By describing the WiFi Direct standard and the\nlimitations of the current implementation of the Android WiFi Direct framework,\nwe present possible solutions to interconnect different groups to create\nmulti-hop ad hoc networks. Experimental results show that our proposed\napproaches are feasible with different overhead in terms of energy consumption\nand delay at the gateway node. Additionally, our experimental results\ndemonstrate the superiority of techniques that exploit the device ability to\nmaintain simultaneous physical connections to multiple groups.", "subject": "Networking and Internet Architecture (cs.NI)"}, {"idx": 7, "title": "Neighborhood covering and independence on two superclasses of cographs", "abstract": "Given a simple graph $G$, a set $C \\subseteq V(G)$ is a neighborhood cover\nset if every edge and vertex of $G$ belongs to some $G[v]$ with $v \\in C$,\nwhere $G[v]$ denotes the subgraph of $G$ induced by the closed neighborhood of\nthe vertex $v$. Two elements of $E(G) \\cup V(G)$ are neighborhood-independent\nif there is no vertex $v\\in V(G)$ such that both elements are in $G[v]$. A set\n$S\\subseteq V(G)\\cup E(G)$ is neighborhood-independent if every pair of\nelements of $S$ is neighborhood-independent. Let $\u03c1_{\\mathrm n}(G)$ be the\nsize of a minimum neighborhood cover set and $\u03b1_{\\mathrm n}(G)$ of a\nmaximum neighborhood-independent set. Lehel and Tuza defined\nneighborhood-perfect graphs $G$ as those where the equality $\u03c1_{\\mathrm\nn}(G') = \u03b1_{\\mathrm n}(G')$ holds for every induced subgraph $G'$ of $G$.\n  In this work we prove forbidden induced subgraph characterizations of the\nclass of neighborhood-perfect graphs, restricted to two superclasses of\ncographs: $P_4$-tidy graphs and tree-cographs. We give as well linear-time\nalgorithms for solving the recognition problem of neighborhood-perfect graphs\nand the problem of finding a minimum neighborhood cover set and a maximum\nneighborhood-independent set in these same classes.", "subject": "Discrete Mathematics (cs.DM)"}, {"idx": 8, "title": "Fast, Safe, and Propellant-Efficient Spacecraft Planning under Clohessy-Wiltshire-Hill Dynamics", "abstract": "This paper presents a sampling-based motion planning algorithm for real-time\nand propellant-optimized autonomous spacecraft trajectory generation in\nnear-circular orbits. Specifically, this paper leverages recent algorithmic\nadvances in the field of robot motion planning to the problem of\nimpulsively-actuated, propellant-optimized rendezvous and proximity operations\nunder the Clohessy-Wiltshire-Hill (CWH) dynamics model. The approach calls upon\na modified version of the Fast Marching Tree (FMT*) algorithm to grow a set of\nfeasible trajectories over a deterministic, low-dispersion set of sample points\ncovering the free state space. To enforce safety, the tree is only grown over\nthe subset of actively-safe samples, from which there exists a feasible\none-burn collision avoidance maneuver that can safely circularize the\nspacecraft orbit along its coasting arc under a given set of potential thruster\nfailures. Key features of the proposed algorithm include: (i) theoretical\nguarantees in terms of trajectory safety and performance, (ii) amenability to\nreal-time implementation, and (iii) generality, in the sense that a large class\nof constraints can be handled directly. As a result, the proposed algorithm\noffers the potential for widespread application, ranging from on-orbit\nsatellite servicing to orbital debris removal and autonomous inspection\nmissions.", "subject": "Systems and Control (eess.SY)"}, {"idx": 9, "title": "GPU-Based Fuzzy C-Means Clustering Algorithm for Image Segmentation", "abstract": "In this paper, a fast and practical GPU-based implementation of Fuzzy\nC-Means(FCM) clustering algorithm for image segmentation is proposed. First, an\nextensive analysis is conducted to study the dependency among the image pixels\nin the algorithm for parallelization. The proposed GPU-based FCM has been\ntested on digital brain simulated dataset to segment white matter(WM), gray\nmatter(GM) and cerebrospinal fluid (CSF) soft tissue regions. The execution\ntime of the sequential FCM is 519 seconds for an image dataset with the size of\n1MB. While the proposed GPU-based FCM requires only 2.33 seconds for the\nsimilar size of image dataset. An estimated 245-fold speedup is measured for\nthe data size of 40 KB on a CUDA device that has 448 processors.", "subject": "Distributed, Parallel, and Cluster Computing (cs.DC)"}, {"idx": 10, "title": "Mimir: Bringing CTables into Practice", "abstract": "The present state of the art in analytics requires high upfront investment of\nhuman effort and computational resources to curate datasets, even before the\nfirst query is posed. So-called pay-as-you-go data curation techniques allow\nthese high costs to be spread out, first by enabling queries over uncertain and\nincomplete data, and then by assessing the quality of the query results. We\ndescribe the design of a system, called Mimir, around a recently introduced\nclass of probabilistic pay-as-you-go data cleaning operators called Lenses.\nMimir wraps around any deterministic database engine using JDBC, extending it\nwith support for probabilistic query processing. Queries processed through\nMimir produce uncertainty-annotated result cursors that allow client\napplications to quickly assess result quality and provenance. We also present a\nGUI that provides analysts with an interactive tool for exploring the\nuncertainty exposed by the system. Finally, we present optimizations that make\nLenses scalable, and validate this claim through experimental evidence.", "subject": "Databases (cs.DB)"}, {"idx": 11, "title": "A wireless physically secure key distribution system", "abstract": "A secure key distribution protocol protected by light's noise was introduced\nin 2003 [Phys. Rev. A 68, 052307 (2003)]. That protocol utilized the shot noise\nof light present in the optical channel (eg., an optical fiber) to restrict\ninformation leaks to an adversary. An initial shared information between the\nlegitimate users allowed them to extract more information from the channel than\nthe one obtained by the adversary. That original paper recognized the need for\na privacy amplification step but no specific protocol was presented. More\nrecently that original idea was improved with a specific privacy amplification\nprotocol [arXiv:1406.1543v2 [cs.CR] 8 Jul 2015] while keeping the use of an\noptical communication channel. This work merges main ideas of the protection\ngiven by the light's noise in a protocol applied to wireless channels. The use\nof a wireless channels together with recorded physical noise was introduced\nfrom 2005 to 2007 (see eg, arXiv:quant-ph/0510011 v2 16 Nov 2005 and\narXiv:0705.2243v2 [quant-ph] 17 May 2007). This work improves those embrionary\nideas of wireless channels secured by recorded optical noise. The need for\nspecific optical channels is eliminated with the wireless variation and opens\nup the possibility to apply the technique to mobile devices. This work\nintroduces this new scheme and calculates the associated security level.", "subject": "Cryptography and Security (cs.CR)"}, {"idx": 12, "title": "Sentiment/Subjectivity Analysis Survey for Languages other than English", "abstract": "Subjective and sentiment analysis have gained considerable attention\nrecently. Most of the resources and systems built so far are done for English.\nThe need for designing systems for other languages is increasing. This paper\nsurveys different ways used for building systems for subjective and sentiment\nanalysis for languages other than English. There are three different types of\nsystems used for building these systems. The first (and the best) one is the\nlanguage specific systems. The second type of systems involves reusing or\ntransferring sentiment resources from English to the target language. The third\ntype of methods is based on using language independent methods. The paper\npresents a separate section devoted to Arabic sentiment analysis.", "subject": "Computation and Language (cs.CL)"}, {"idx": 13, "title": "Understanding Symmetric Smoothing Filters: A Gaussian Mixture Model Perspective", "abstract": "Many patch-based image denoising algorithms can be formulated as applying a\nsmoothing filter to the noisy image. Expressed as matrices, the smoothing\nfilters must be row normalized so that each row sums to unity. Surprisingly, if\nwe apply a column normalization before the row normalization, the performance\nof the smoothing filter can often be significantly improved. Prior works showed\nthat such performance gain is related to the Sinkhorn-Knopp balancing\nalgorithm, an iterative procedure that symmetrizes a row-stochastic matrix to a\ndoubly-stochastic matrix. However, a complete understanding of the performance\ngain phenomenon is still lacking.\n  In this paper, we study the performance gain phenomenon from a statistical\nlearning perspective. We show that Sinkhorn-Knopp is equivalent to an\nExpectation-Maximization (EM) algorithm of learning a Gaussian mixture model of\nthe image patches. By establishing the correspondence between the steps of\nSinkhorn-Knopp and the EM algorithm, we provide a geometrical interpretation of\nthe symmetrization process. This observation allows us to develop a new\ndenoising algorithm called Gaussian mixture model symmetric smoothing filter\n(GSF). GSF is an extension of the Sinkhorn-Knopp and is a generalization of the\noriginal smoothing filters. Despite its simple formulation, GSF outperforms\nmany existing smoothing filters and has a similar performance compared to\nseveral state-of-the-art denoising algorithms.", "subject": "Computer Vision and Pattern Recognition (cs.CV)"}, {"idx": 14, "title": "Stability and bifurcation properties of the algorithms for keeping of differential equations solutions on the required level", "abstract": "Algorithms of control of differential equations solutions are under\ninvestigation in the article. Idealized and real modifications of the\nalgorithms are distinguished. An equation, which can be the base equation for\ninvestigation of the idealized algorithms properties, is constructed. The\ndifference appearing for real systems and real algorithms is for separate\ninvestigation. This difference tends to zero under tending to zero of the time\nstep of control. If the systems of equations satisfy or almost satisfy some\nproperties for which the algorithms are intended, then the results are similar\nnumerically as well. One of the algorithms demonstrates high reliability.\nAnother one is of more complex properties. Bifurcations, periodic solutions and\nstrange attractors are possible in both algorithms in addition to stable steady\nstates.", "subject": "Numerical Analysis (math.NA)"}, {"idx": 15, "title": "Discriminative Sparsity for Sonar ATR", "abstract": "Advancements in Sonar image capture have enabled researchers to apply\nsophisticated object identification algorithms in order to locate targets of\ninterest in images such as mines. Despite progress in this field, modern sonar\nautomatic target recognition (ATR) approaches lack robustness to the amount of\nnoise one would expect in real-world scenarios, the capability to handle\nblurring incurred from the physics of image capture, and the ability to excel\nwith relatively few training samples. We address these challenges by adapting\nmodern sparsity-based techniques with dictionaries comprising of training from\neach class. We develop new discriminative (as opposed to generative) sparse\nrepresentations which can help automatically classify targets in Sonar imaging.\nUsing a simulated SAS data set from the Naval Surface Warfare Center (NSWC), we\nobtained compelling classification rates for multi-class problems even in cases\nwith considerable noise and sparsity in training samples.", "subject": "Computer Vision and Pattern Recognition (cs.CV)"}, {"idx": 16, "title": "Improving Performance of IEEE 802.11 by a Dynamic Control Backoff Algorithm Under Unsaturated Traffic Loads", "abstract": "The IEEE 802.11 backoff algorithm is very important for controlling system\nthroughput over contentionbased wireless networks. For this reason, there are\nmany studies on wireless network performance focus on developing backoff\nalgorithms. However, most existing models are based on saturated traffic loads,\nwhich are not a real representation of actual network conditions. In this\npaper, a dynamic control backoff time algorithm is proposed to enhance both\ndelay and throughput performance of the IEEE 802.11 distributed coordination\nfunction. This algorithm considers the distinction between high and low traffic\nloads in order to deal with unsaturated traffic load conditions. In particular,\nthe equilibrium point analysis model is used to represent the algorithm under\nvarious traffic load conditions. Results of extensive simulation experiments\nillustrate that the proposed algorithm yields better performance throughput and\na better average transmission packet delay than related algorithms.", "subject": "Networking and Internet Architecture (cs.NI)"}, {"idx": 17, "title": "On some bounds for symmetric tensor rank of multiplication in finite fields", "abstract": "We establish new upper bounds about symmetric bilinear complexity in any\nextension of finite fields. Note that these bounds are not asymptotical but\nuniform.\n  Moreover we give examples of Shimura curves that do not descend over their\nfield of moduli, which discusses the validity of certain published bounds.", "subject": "Information Theory (cs.IT)"}, {"idx": 18, "title": "The Reduced-Order Hybrid Monte Carlo Sampling Smoother", "abstract": "Hybrid Monte-Carlo (HMC) sampling smoother is a fully non-Gaussian\nfour-dimensional data assimilation algorithm that works by directly sampling\nthe posterior distribution formulated in the Bayesian framework. The smoother\nin its original formulation is computationally expensive due to the intrinsic\nrequirement of running the forward and adjoint models repeatedly. Here we\npresent computationally efficient versions of the HMC sampling smoother based\non reduced-order approximations of the underlying model dynamics. The schemes\ndeveloped herein are tested numerically using the shallow-water equations model\non Cartesian coordinates. The results reveal that the reduced-order versions of\nthe smoother are capable of accurately capturing the posterior probability\ndensity, while being significantly faster than the original full order\nformulation.", "subject": "Numerical Analysis (math.NA)"}, {"idx": 19, "title": "Group Centrality for Semantic Networks: a SWOT analysis featuring Random Walks", "abstract": "Group centrality is an extension of the classical notion of centrality for\nindividuals, to make it applicable to sets of them. We perform a SWOT\n(strengths, weaknesses, opportunities and threats) analysis of the use of group\ncentrality in semantic networks, for different centrality notions: degree,\ncloseness, betweenness, giving prominence to random walks. Among our main\nresults stand out the relevance and NP-hardness of the problem of finding the\nmost central set in a semantic network for an specific centrality measure.", "subject": "Social and Information Networks (cs.SI)"}, {"idx": 20, "title": "Detecting the historical roots of tribology research: a bibliometric analysis", "abstract": "In this study, the historical roots of tribology are investigated using a\nnewly developed scientometric method called Referenced Publication Years\nSpectroscopy. The study is based on cited references in tribology research\npublications. The Science Citation Index Expanded is used as data source. The\nresults show that RPYS has the potential to identify the important publications\n: Most of the publications which have been identified in this study as highly\ncited (referenced) publications are landmark publications in the field of\ntribology.", "subject": "Digital Libraries (cs.DL)"}, {"idx": 21, "title": "Tensor Sparse and Low-Rank based Submodule Clustering Method for Multi-way Data", "abstract": "A new submodule clustering method via sparse and low-rank representation for\nmulti-way data is proposed in this paper. Instead of reshaping multi-way data\ninto vectors, this method maintains their natural orders to preserve data\nintrinsic structures, e.g., image data kept as matrices. To implement\nclustering, the multi-way data, viewed as tensors, are represented by the\nproposed tensor sparse and low-rank model to obtain its submodule\nrepresentation, called a free module, which is finally used for spectral\nclustering. The proposed method extends the conventional subspace clustering\nmethod based on sparse and low-rank representation to multi-way data submodule\nclustering by combining t-product operator. The new method is tested on several\npublic datasets, including synthetical data, video sequences and toy images.\nThe experiments show that the new method outperforms the state-of-the-art\nmethods, such as Sparse Subspace Clustering (SSC), Low-Rank Representation\n(LRR), Ordered Subspace Clustering (OSC), Robust Latent Low Rank Representation\n(RobustLatLRR) and Sparse Submodule Clustering method (SSmC).", "subject": "Computer Vision and Pattern Recognition (cs.CV)"}, {"idx": 22, "title": "Information Exchange in Randomly Deployed Dense WSNs with Wireless Energy Harvesting Capabilities", "abstract": "As large-scale dense and often randomly deployed wireless sensor networks\n(WSNs) become widespread, local information exchange between co-located sets of\nnodes may play a significant role in handling the excessive traffic volume.\nMoreover, to account for the limited life-span of the wireless devices,\nharvesting the energy of the network transmissions provides significant\nbenefits to the lifetime of such networks. In this paper, we study the\nperformance of communication in dense networks with wireless energy harvesting\n(WEH)-enabled sensor nodes. In particular, we examine two different\ncommunication scenarios (direct and cooperative) for data exchange and we\nprovide theoretical expressions for the probability of successful\ncommunication. Then, considering the importance of lifetime in WSNs, we employ\nstate-of-the-art WEH techniques and realistic energy converters, quantifying\nthe potential energy gains that can be achieved in the network. Our analytical\nderivations, which are validated by extensive Monte-Carlo simulations,\nhighlight the importance of WEH in dense networks and identify the trade-offs\nbetween the direct and cooperative communication scenarios.", "subject": "Information Theory (cs.IT)"}, {"idx": 23, "title": "PI : a Parallel in-memory skip list based Index", "abstract": "Due to the coarse granularity of data accesses and the heavy use of latches,\nindices in the B-tree family are not efficient for in-memory databases,\nespecially in the context of today's multi-core architecture.\n  In this paper, we present PI, a Parallel in-memory skip list based Index that\nlends itself naturally to the parallel and concurrent environment, particularly\nwith non-uniform memory access. In PI, incoming queries are collected, and\ndisjointly distributed among multiple threads for processing to avoid the use\nof latches. For each query, PI traverses the index in a Breadth-First-Search\n(BFS) manner to find the list node with the matching key, exploiting SIMD\nprocessing to speed up the search process. In order for query processing to be\nlatch-free, PI employs a light-weight communication protocol that enables\nthreads to re-distribute the query workload among themselves such that each\nlist node that will be modified as a result of query processing will be\naccessed by exactly one thread. We conducted extensive experiments, and the\nresults show that PI can be up to three times as fast as the Masstree, a\nstate-of-the-art B-tree based index.", "subject": "Databases (cs.DB)"}, {"idx": 24, "title": "A Parameterized Algorithm for Bounded-Degree Vertex Deletion", "abstract": "The $d$-bounded-degree vertex deletion problem, to delete at most $k$\nvertices in a given graph to make the maximum degree of the remaining graph at\nmost $d$, finds applications in computational biology, social network analysis\nand some others. It can be regarded as a special case of the $(d+2)$-hitting\nset problem and generates the famous vertex cover problem. The\n$d$-bounded-degree vertex deletion problem is NP-hard for each fixed $d\\geq 0$.\nIn terms of parameterized complexity, the problem parameterized by $k$ is\nW[2]-hard for unbounded $d$ and fixed-parameter tractable for each fixed $d\\geq\n0$. Previously, (randomized) parameterized algorithms for this problem with\nrunning time bound $O^*((d+1)^k)$ are only known for $d\\leq2$. In this paper,\nwe give a uniform parameterized algorithm deterministically solving this\nproblem in $O^*((d+1)^k)$ time for each $d\\geq 3$. Note that it is an open\nproblem whether the $d'$-hitting set problem can be solved in $O^*((d'-1)^k)$\ntime for $d'\\geq 3$. Our result answers this challenging open problem\naffirmatively for a special case. Furthermore, our algorithm also gets a\nrunning time bound of $O^*(3.0645^k)$ for the case that $d=2$, improving the\nprevious deterministic bound of $O^*(3.24^k)$.", "subject": "Data Structures and Algorithms (cs.DS)"}, {"idx": 25, "title": "On a generalization of Nemhauser and Trotter's local optimization theorem", "abstract": "Fellows, Guo, Moser and Niedermeier~[JCSS2011] proved a generalization of\nNemhauser and Trotter's theorem, which applies to \\textsc{Bounded-Degree Vertex\nDeletion} (for a fixed integer $d\\geq 0$, to delete $k$ vertices of the input\ngraph to make the maximum degree of it $\\leq d$) and gets a linear-vertex\nkernel for $d=0$ and $1$, and a superlinear-vertex kernel for each $d\\geq 2$.\nIt is still left as an open problem whether \\textsc{Bounded-Degree Vertex\nDeletion} admits a linear-vertex kernel for each $d\\geq 3$. In this paper, we\nrefine the generalized Nemhauser and Trotter's theorem and get a linear-vertex\nkernel for each $d\\geq 0$.", "subject": "Data Structures and Algorithms (cs.DS)"}, {"idx": 26, "title": "Game-Theoretic Model of Incentivizing Privacy-Aware Users to Consent to Location Tracking", "abstract": "Nowadays, mobile users have a vast number of applications and services at\ntheir disposal. Each of these might impose some privacy threats on users'\n\"Personally Identifiable Information\" (PII). Location privacy is a crucial part\nof PII, and as such, privacy-aware users wish to maximize it. This privacy can\nbe, for instance, threatened by a company, which collects users' traces and\nshares them with third parties. To maximize their location privacy, users can\ndecide to get offline so that the company cannot localize their devices. The\nlonger a user stays connected to a network, the more services he might receive,\nbut his location privacy decreases. In this paper, we analyze the trade-off\nbetween location privacy, the level of services that a user experiences, and\nthe profit of the company. To this end, we formulate a Stackelberg Bayesian\ngame between the User (follower) and the Company (leader). We present\ntheoretical results characterizing the equilibria of the game. To the best of\nour knowledge, our work is the first to model the economically rational\ndecision-making of the service provider (i.e., the Company) in conjunction with\nthe rational decision-making of users who wish to protect their location\nprivacy. To evaluate the performance of our approach, we have used real-data\nfrom a testbed, and we have also shown that the game-theoretic strategy of the\nCompany outperforms non-strategic methods. Finally, we have considered\ndifferent User privacy types, and have determined the service level that\nincentivizes the User to stay connected as long as possible.", "subject": "Computer Science and Game Theory (cs.GT)"}, {"idx": 27, "title": "On Quantitatively Measuring Controllability of Complex Networks", "abstract": "This letter deals with the controllability issue of complex networks. An\nindex is chosen to quantitatively measure the extent of controllability of\ngiven network. The effect of this index is analyzed based on empirical studies\non various classes of network topologies, such as random network, small-world\nnetwork, and scale-free network.", "subject": "Systems and Control (eess.SY)"}, {"idx": 28, "title": "Interdependent Relationships in Game Theory: A Generalized Model", "abstract": "A generalized model of games is proposed, in which cooperative games and\nnon-cooperative games are special cases. Some games that are neither\ncooperative nor non-cooperative can be expressed and analyzed. The model is\nbased on relationships and supposed relationships between players. A\nrelationship is a numerical value that denotes how one player cares for the\npayoffs of another player, while a supposed relationship is another numerical\nvalue that denotes a player's belief about the relationship between two\nplayers. The players choose their strategies by taking into consideration not\nonly the material payoffs but also relationships and their change. Two games, a\nprisoners' dilemma and a repeated ultimatum game, are analyzed as examples of\napplication of this model.", "subject": "Computer Science and Game Theory (cs.GT)"}, {"idx": 29, "title": "Cohort Query Processing", "abstract": "Modern Internet applications often produce a large volume of user activity\nrecords. Data analysts are interested in cohort analysis, or finding unusual\nuser behavioral trends, in these large tables of activity records. In a\ntraditional database system, cohort analysis queries are both painful to\nspecify and expensive to evaluate. We propose to extend database systems to\nsupport cohort analysis. We do so by extending SQL with three new operators. We\ndevise three different evaluation schemes for cohort query processing. Two of\nthem adopt a non-intrusive approach. The third approach employs a columnar\nbased evaluation scheme with optimizations specifically designed for cohort\nquery processing. Our experimental results confirm the performance benefits of\nour proposed columnar database system, compared against the two non-intrusive\napproaches that implement cohort queries on top of regular relational\ndatabases.", "subject": "Databases (cs.DB)"}, {"idx": 30, "title": "The Security of WebRTC", "abstract": "WebRTC is an API that allows users to share streaming information, whether it\nis text, sound, video or files. It is supported by all major browsers and has a\nflexible underlying infrastructure. In this study we review current WebRTC\nstructure and security in the contexts of communication disruption,\nmodification and eavesdropping. In addition, we examine WebRTC security in a\nfew representative scenarios, setting up and simulating real WebRTC\nenvironments and attacks.", "subject": "Cryptography and Security (cs.CR)"}, {"idx": 31, "title": "An Improved Intelligent Agent for Mining Real-Time Databases Using Modified Cortical Learning Algorithms", "abstract": "Cortical Learning Algorithms based on the Hierarchical Temporal Memory, HTM\nhave been developed by Numenta Incorporation from which variations and\nmodifications are currently being investigated upon. HTM offers better promises\nas a future computational model of the neocortex the seat of intelligence in\nthe brain. Currently, intelligent agents are embedded in almost every modern\nday electronic system found in homes, offices and industries worldwide. In this\npaper, we present a first step in realising useful HTM like applications\nspecifically for mining a synthetic and real time dataset based on a novel\nintelligent agent framework, and demonstrate how a modified version of this\nvery important computational technique will lead to improved recognition.", "subject": "Neural and Evolutionary Computing (cs.NE)"}, {"idx": 32, "title": "A Unified Framework for Compositional Fitting of Active Appearance Models", "abstract": "Active Appearance Models (AAMs) are one of the most popular and\nwell-established techniques for modeling deformable objects in computer vision.\nIn this paper, we study the problem of fitting AAMs using Compositional\nGradient Descent (CGD) algorithms. We present a unified and complete view of\nthese algorithms and classify them with respect to three main characteristics:\ni) cost function; ii) type of composition; and iii) optimization method.\nFurthermore, we extend the previous view by: a) proposing a novel Bayesian cost\nfunction that can be interpreted as a general probabilistic formulation of the\nwell-known project-out loss; b) introducing two new types of composition,\nasymmetric and bidirectional, that combine the gradients of both image and\nappearance model to derive better conver- gent and more robust CGD algorithms;\nand c) providing new valuable insights into existent CGD algorithms by\nreinterpreting them as direct applications of the Schur complement and the\nWiberg method. Finally, in order to encourage open research and facilitate\nfuture comparisons with our work, we make the implementa- tion of the\nalgorithms studied in this paper publicly available as part of the Menpo\nProject.", "subject": "Computer Vision and Pattern Recognition (cs.CV)"}, {"idx": 33, "title": "Susceptibility of texture measures to noise: an application to lung tumor CT images", "abstract": "Five different texture methods are used to investigate their susceptibility\nto subtle noise occurring in lung tumor Computed Tomography (CT) images caused\nby acquisition and reconstruction deficiencies. Noise of Gaussian and Rayleigh\ndistributions with varying mean and variance was encountered in the analyzed CT\nimages. Fisher and Bhattacharyya distance measures were used to differentiate\nbetween an original extracted lung tumor region of interest (ROI) with a\nfiltered and noisy reconstructed versions. Through examining the texture\ncharacteristics of the lung tumor areas by five different texture measures, it\nwas determined that the autocovariance measure was least affected and the gray\nlevel co-occurrence matrix was the most affected by noise. Depending on the\nselected ROI size, it was concluded that the number of extracted features from\neach texture measure increases susceptibility to noise.", "subject": "Computer Vision and Pattern Recognition (cs.CV)"}, {"idx": 34, "title": "A fractal dimension based optimal wavelet packet analysis technique for classification of meningioma brain tumours", "abstract": "With the heterogeneous nature of tissue texture, using a single resolution\napproach for optimum classification might not suffice. In contrast, a\nmultiresolution wavelet packet analysis can decompose the input signal into a\nset of frequency subbands giving the opportunity to characterise the texture at\nthe appropriate frequency channel. An adaptive best bases algorithm for optimal\nbases selection for meningioma histopathological images is proposed, via\napplying the fractal dimension (FD) as the bases selection criterion in a\ntree-structured manner. Thereby, the most significant subband that better\nidentifies texture discontinuities will only be chosen for further\ndecomposition, and its fractal signature would represent the extracted feature\nvector for classification. The best basis selection using the FD outperformed\nthe energy based selection approaches, achieving an overall classification\naccuracy of 91.25% as compared to 83.44% and 73.75% for the co-occurrence\nmatrix and energy texture signatures; respectively.", "subject": "Computer Vision and Pattern Recognition (cs.CV)"}, {"idx": 35, "title": "Supervised Texture Segmentation: A Comparative Study", "abstract": "This paper aims to compare between four different types of feature extraction\napproaches in terms of texture segmentation. The feature extraction methods\nthat were used for segmentation are Gabor filters (GF), Gaussian Markov random\nfields (GMRF), run-length matrix (RLM) and co-occurrence matrix (GLCM). It was\nshown that the GF performed best in terms of quality of segmentation while the\nGLCM localises the texture boundaries better as compared to the other methods.", "subject": "Computer Vision and Pattern Recognition (cs.CV)"}, {"idx": 36, "title": "Faster GPU Based Genetic Programming Using A Two Dimensional Stack", "abstract": "Genetic Programming (GP) is a computationally intensive technique which also\nhas a high degree of natural parallelism. Parallel computing architectures have\nbecome commonplace especially with regards Graphics Processing Units (GPU).\nHence, versions of GP have been implemented that utilise these highly parallel\ncomputing platforms enabling significant gains in the computational speed of GP\nto be achieved. However, recently a two dimensional stack approach to GP using\na multi-core CPU also demonstrated considerable performance gains. Indeed,\nperformances equivalent to or exceeding that achieved by a GPU were\ndemonstrated. This paper will demonstrate that a similar two dimensional stack\napproach can also be applied to a GPU based approach to GP to better exploit\nthe underlying technology. Performance gains are achieved over a standard\nsingle dimensional stack approach when utilising a GPU. Overall, a peak\ncomputational speed of over 55 billion Genetic Programming Operations per\nSecond are observed, a two fold improvement over the best GPU based single\ndimensional stack approach from the literature.", "subject": "Distributed, Parallel, and Cluster Computing (cs.DC)"}, {"idx": 37, "title": "Supervised Dimensionality Reduction via Distance Correlation Maximization", "abstract": "In our work, we propose a novel formulation for supervised dimensionality\nreduction based on a nonlinear dependency criterion called Statistical Distance\nCorrelation, Szekely et. al. (2007). We propose an objective which is free of\ndistributional assumptions on regression variables and regression model\nassumptions. Our proposed formulation is based on learning a low-dimensional\nfeature representation $\\mathbf{z}$, which maximizes the squared sum of\nDistance Correlations between low dimensional features $\\mathbf{z}$ and\nresponse $y$, and also between features $\\mathbf{z}$ and covariates\n$\\mathbf{x}$. We propose a novel algorithm to optimize our proposed objective\nusing the Generalized Minimization Maximizaiton method of \\Parizi et. al.\n(2015). We show superior empirical results on multiple datasets proving the\neffectiveness of our proposed approach over several relevant state-of-the-art\nsupervised dimensionality reduction methods.", "subject": "Machine Learning (cs.LG)"}, {"idx": 38, "title": "Fixed points of adjoint functors enriched in a quantaloid", "abstract": "Representation theorems are established for fixed points of adjoint functors\nbetween categories enriched in a small quantaloid. In a very general setting\nthese results set up a common framework for representation theorems of concept\nlattices in formal concept analysis (FCA) and rough set theory (RST), which not\nonly extend the realm of formal contexts to multi-typed and multi-valued ones,\nbut also provide a general approach to construct various kinds of\nrepresentation theorems. Besides incorporating several well-known\nrepresentation theorems in FCA and RST as well as formulating new ones, it is\nshown that concept lattices in RST can always be represented as those in FCA\nthrough relative pseudo-complements of the given contexts, especially if the\ncontexts are valued in a non-Girard quantaloid.", "subject": "Logic in Computer Science (cs.LO)"}, {"idx": 39, "title": "Non-Concept Software Subsystems: Tangible and Intangible", "abstract": "Concepts modified by a Non- prefix apparently denote a negation, an opposite\nof the concept without this prefix. But, generally the situation is rather\nsubtle: non- implies only partial negation and the concept suggests preserved\nidentity with some reduced quality or absent attribute. In this work tangible\nand intangible software subsystems based upon Non- concepts are defined and\npluggable ontologies are proposed for their representation. Pluggable\nontologies are a kind of nano-ontologies, which by their minimal size\nfacilitate fast composition of new software subsystems. These ontologies are\nmade pluggable by Design Sockets, a novel kind of class. These are abstract\nconnectors for removed/added parts, functionalities or identities, and for\nsubdued qualities. Design Sockets are the basis of a Design Pattern for\ndynamically modifiable software systems. Pragmatic implications of Non-\nconcepts include manageable design of product lines with multiple models. Non-\nconcepts are also relevant to the controversy whether composition is or is not\nidentity. The resolution is not sharp. Identity is entangled with composition,\nand is preserved to a certain extent, until further removal causes identity\nbreakdown.", "subject": "Software Engineering (cs.SE)"}, {"idx": 40, "title": "Funding acknowledgment analysis:Queries and Caveats", "abstract": "Thomson Reuters' Web of Science (WoS) began systematically collecting\nacknowledgment information in August 2008. Since then, bibliometric analysis of\nfunding acknowledgment (FA) has been growing and has aroused intense interest\nand attention from both academia and policy makers. Examining the distribution\nof FA by citation index database, by language, and by acknowledgment type, we\nnoted coverage limitations and potential biases in each analysis. We argue that\nin spite of its great value, bibliometric analysis of FA should be used with\ncaution.", "subject": "Digital Libraries (cs.DL)"}, {"idx": 41, "title": "Contrastive Entropy: A new evaluation metric for unnormalized language models", "abstract": "Perplexity (per word) is the most widely used metric for evaluating language\nmodels. Despite this, there has been no dearth of criticism for this metric.\nMost of these criticisms center around lack of correlation with extrinsic\nmetrics like word error rate (WER), dependence upon shared vocabulary for model\ncomparison and unsuitability for unnormalized language model evaluation. In\nthis paper, we address the last problem and propose a new discriminative\nentropy based intrinsic metric that works for both traditional word level\nmodels and unnormalized language models like sentence level models. We also\npropose a discriminatively trained sentence level interpretation of recurrent\nneural network based language model (RNN) as an example of unnormalized\nsentence level model. We demonstrate that for word level models, contrastive\nentropy shows a strong correlation with perplexity. We also observe that when\ntrained at lower distortion levels, sentence level RNN considerably outperforms\ntraditional RNNs on this new metric.", "subject": "Computation and Language (cs.CL)"}, {"idx": 42, "title": "Greedy online colouring with buffering", "abstract": "We consider the problem of online graph colouring. Whenever a node is\nrequested, a colour must be assigned to the node, and this colour must be\ndifferent from the colours of any of its neighbours. According to the greedy\nalgorithm the node is coloured by the colour with the smallest possible $k$.\n  The goal is to use as few colours as possible. We propose an algorithm, where\nthe node is coloured not immediately, but only after the collection of next\nrequests stored in the buffer of size $j$. In other words, the first node in\nthe buffer is coloured definitively taking into account all possible\ncolourisations of the remaining nodes in the buffer. If there are $r$ possible\ncorrected colourings, then the one with the probability $1/r$ is chosen. The\nfirst coloured node is removed from the buffer to enable the entrance of the\nnext request. A number of colours in a two examples of graphs: crown graphs and\nKneser graphs have been analysed.", "subject": "Discrete Mathematics (cs.DM)"}, {"idx": 43, "title": "Underlay Spectrum Sharing Techniques with In-band Full-Duplex Systems using Improper Gaussian Signaling", "abstract": "Sharing the spectrum with in-band full-duplex (FD) primary users (PU) is a\nchallenging and interesting problem in the underlay cognitive radio (CR)\nsystems. The self-interference introduced at the primary network may\ndramatically impede the secondary user (SU) opportunity to access the spectrum.\nTo tackle this problem, we use the so-called improper Gaussian signaling.\nParticularly, we assume a system with a SU pair working in a half-duplex mode\nthat uses improper Gaussian signaling while the FD PU pair implements the\nregular proper Gaussian signaling. First, we derive a closed form expression\nand an upper bound for the SU and PU outage probabilities, respectively.\nSecond, we optimize the SU signal parameters to minimize its outage probability\nwhile maintaining the required PU quality-of-service based on the average\nchannel state information (CSI). Moreover, we provide the conditions to reap\nmerits from employing improper Gaussian signaling at the SU. Third, we design\nthe SU signal parameters based on perfect knowledge of its direct link\ninstantaneous CSI and investigate all benefits that can be achieved at both the\nSU and PU. Finally, we provide some numerical results that demonstrate the\nadvantages of using improper Gaussian signaling to access the spectrum of the\nFD PU.", "subject": "Information Theory (cs.IT)"}, {"idx": 44, "title": "Image Resolution Enhancement by Using Interpolation Followed by Iterative Back Projection", "abstract": "In this paper, we propose a new super resolution technique based on the\ninterpolation followed by registering them using iterative back projection\n(IBP). Low resolution images are being interpolated and then the interpolated\nimages are being registered in order to generate a sharper high resolution\nimage. The proposed technique has been tested on Lena, Elaine, Pepper, and\nBaboon. The quantitative peak signal-to-noise ratio (PSNR) and structural\nsimilarity index (SSIM) results as well as the visual results show the\nsuperiority of the proposed technique over the conventional and state-of-art\nimage super resolution techniques. For Lena's image, the PSNR is 6.52 dB higher\nthan the bicubic interpolation.", "subject": "Computer Vision and Pattern Recognition (cs.CV)"}, {"idx": 45, "title": "Frequency Estimation of Multiple Sinusoids with Sub-Nyquist Sampling Sequences", "abstract": "In some applications of frequency estimation, the frequencies of multiple\nsinusoids are required to be estimated from sub-Nyquist sampling sequences. In\nthis paper, we propose a novel method based on subspace techniques to estimate\nthe frequencies by using under-sampled samples. We analyze the impact of\nunder-sampling and demonstrate that three sub-Nyquist sequences are general\nenough to estimate the frequencies under some condition. The frequencies\nestimated from one sequence are unfolded in frequency domain, and then the\nother two sequences are used to pick the correct frequencies from all possible\nfrequencies. Simulations illustrate the validity of the theory. Numerical\nresults show that this method is feasible and accurate at quite low sampling\nrates.", "subject": "Information Theory (cs.IT)"}, {"idx": 46, "title": "Firefighting on Trees Beyond Integrality Gaps", "abstract": "The Firefighter problem and a variant of it, known as Resource Minimization\nfor Fire Containment (RMFC), are natural models for optimal inhibition of\nharmful spreading processes. Despite considerable progress on several fronts,\nthe approximability of these problems is still badly understood. This is the\ncase even when the underlying graph is a tree, which is one of the most-studied\ngraph structures in this context and the focus of this paper. In their simplest\nversion, a fire spreads from one fixed vertex step by step from burning to\nadjacent non-burning vertices, and at each time step, $B$ many non-burning\nvertices can be protected from catching fire. The Firefighter problem asks, for\na given $B$, to maximize the number of vertices that will not catch fire,\nwhereas RMFC (on a tree) asks to find the smallest $B$ that allows for saving\nall leaves of the tree. Prior to this work, the best known approximation ratios\nwere an $O(1)$-approximation for the Firefighter problem and an $O(\\log^*\nn)$-approximation for RMFC, both being LP-based and essentially matching the\nintegrality gaps of two natural LP relaxations.\n  We improve on both approximations by presenting a PTAS for the Firefighter\nproblem and an $O(1)$-approximation for RMFC, both qualitatively matching the\nknown hardness results. Our results are obtained through a combination of the\nknown LPs with several new techniques, which allow for efficiently enumerating\nsubsets of super-constant size of a good solution to obtain stronger LPs.", "subject": "Data Structures and Algorithms (cs.DS)"}, {"idx": 47, "title": "Interactive Proof-of-stake", "abstract": "The paper examines decentralized cryptocurrency protocols that are based on\nthe use of internal tokens as identity tools. An analysis of security problems\nwith popular Proof-of-stake consensus protocols is provided. A new protocol,\nInteractive Proof-of-stake, is proposed. The main ideas of the protocol are to\nreduce a number of variables a miner can iterate over to a minimum and also to\nbring a communication into block generation. The protocol is checked against\nknown attacks. It is shown that Interactive Proof-of-stake is more secure than\ncurrent pure Proof-of-stake protocols.", "subject": "Cryptography and Security (cs.CR)"}, {"idx": 48, "title": "Structure-Preserving Sparsification Methods for Social Networks", "abstract": "Sparsification reduces the size of networks while preserving structural and\nstatistical properties of interest. Various sparsifying algorithms have been\nproposed in different contexts. We contribute the first systematic conceptual\nand experimental comparison of \\textit{edge sparsification} methods on a\ndiverse set of network properties. It is shown that they can be understood as\nmethods for rating edges by importance and then filtering globally or locally\nby these scores. We show that applying a local filtering technique improves the\npreservation of all kinds of properties. In addition, we propose a new\nsparsification method (\\textit{Local Degree}) which preserves edges leading to\nlocal hub nodes. All methods are evaluated on a set of social networks from\nFacebook, Google+, Twitter and LiveJournal with respect to network properties\nincluding diameter, connected components, community structure, multiple node\ncentrality measures and the behavior of epidemic simulations. In order to\nassess the preservation of the community structure, we also include experiments\non synthetically generated networks with ground truth communities. Experiments\nwith our implementations of the sparsification methods (included in the\nopen-source network analysis tool suite NetworKit) show that many network\nproperties can be preserved down to about 20\\% of the original set of edges for\nsparse graphs with a reasonable density. The experimental results allow us to\ndifferentiate the behavior of different methods and show which method is\nsuitable with respect to which property. While our Local Degree method is best\nfor preserving connectivity and short distances, other newly introduced local\nvariants are best for preserving the community structure.", "subject": "Social and Information Networks (cs.SI)"}, {"idx": 49, "title": "Wavelet Scattering on the Pitch Spiral", "abstract": "We present a new representation of harmonic sounds that linearizes the\ndynamics of pitch and spectral envelope, while remaining stable to deformations\nin the time-frequency plane. It is an instance of the scattering transform, a\ngeneric operator which cascades wavelet convolutions and modulus\nnonlinearities. It is derived from the pitch spiral, in that convolutions are\nsuccessively performed in time, log-frequency, and octave index. We give a\nclosed-form approximation of spiral scattering coefficients for a nonstationary\ngeneralization of the harmonic source-filter model.", "subject": "Sound (cs.SD)"}, {"idx": 50, "title": "Identification of long-term concept-symbols among citations: Can documents be clustered in terms of common intellectual histories?", "abstract": "\"Citation classics\" are not only highly cited, but also cited during several\ndecades. We test whether the peaks in the spectrograms generated by Reference\nPublication Years Spectroscopy (RPYS) indicate such long-term impact by\ncomparing across RPYS for subsequent time intervals. Multi-RPYS enables us to\ndistinguish between short-term citation peaks at the research front that decay\nwithin ten years versus historically constitutive (long-term) citations that\nfunction as concept symbols (Small, 1978). Using these constitutive citations,\none is able to cluster document sets (e.g., journals) in terms of\nintellectually shared histories. We test this premise by clustering 40 journals\nin the Web of Science Category of Information and Library Science using\nmulti-RPYS. It follows that RPYS can not only be used for retrieving roots of\nsets under study (cited), but also for algorithmic historiography of the citing\nsets. Significant references are historically rooted symbols among other\ncitations that function as currency.", "subject": "Digital Libraries (cs.DL)"}, {"idx": 51, "title": "An Empirical Comparison of Big Graph Frameworks in the Context of Network Analysis", "abstract": "Complex networks are relational data sets commonly represented as graphs. The\nanalysis of their intricate structure is relevant to many areas of science and\ncommerce, and data sets may reach sizes that require distributed storage and\nprocessing. We describe and compare programming models for distributed\ncomputing with a focus on graph algorithms for large-scale complex network\nanalysis. Four frameworks - GraphLab, Apache Giraph, Giraph++ and Apache Flink\n- are used to implement algorithms for the representative problems Connected\nComponents, Community Detection, PageRank and Clustering Coefficients. The\nimplementations are executed on a computer cluster to evaluate the frameworks'\nsuitability in practice and to compare their performance to that of the\nsingle-machine, shared-memory parallel network analysis package NetworKit. Out\nof the distributed frameworks, GraphLab and Apache Giraph generally show the\nbest performance. In our experiments a cluster of eight computers running\nApache Giraph enables the analysis of a network with about 2 billion edges,\nwhich is too large for a single machine of the same type. However, for networks\nthat fit into memory of one machine, the performance of the shared-memory\nparallel implementation is far better than the distributed ones. The study\nprovides experimental evidence for selecting the appropriate framework\ndepending on the task and data volume.", "subject": "Distributed, Parallel, and Cluster Computing (cs.DC)"}, {"idx": 52, "title": "Capacity Enlargement Of The PVD Steganography Method Using The GLM Technique", "abstract": "In most steganographic methods, increasing in the capacity leads to decrease\nin the quality of the stego-image, so in this paper, we propose to combine two\nexisting techniques, Pixel value differencing and Gray Level Modification, to\ncome up with a hybrid steganography scheme which can hide more information\nwithout having to compromise much on the quality of the stego-image.\nExperimental results demonstrate that the proposed approach has larger capacity\nwhile its results are imperceptible. In comparison with original PVD method\ncriterion of the quality is declined by 2% dB averagely while the capacity is\nincreased around 25%.", "subject": "Multimedia (cs.MM)"}, {"idx": 53, "title": "How can one sample images with sampling rates close to the theoretical minimum?", "abstract": "A problem is addressed of minimization of the number of measurements needed\nfor digital image acquisition and reconstruction with a given accuracy. A\nsampling theory based method of image sampling and reconstruction is suggested\nthat allows to draw near the minimal rate of image sampling defined by the\nsampling theory. Presented and discussed are also results of experimental\nverification of the method and its possible applicability extensions.", "subject": "Computer Vision and Pattern Recognition (cs.CV)"}, {"idx": 54, "title": "When more of the same is better", "abstract": "Problem solving (e.g., drug design, traffic engineering, software\ndevelopment) by task forces represents a substantial portion of the economy of\ndeveloped countries. Here we use an agent-based model of cooperative problem\nsolving systems to study the influence of diversity on the performance of a\ntask force. We assume that agents cooperate by exchanging information on their\npartial success and use that information to imitate the more successful agent\nin the system -- the model. The agents differ only in their propensities to\ncopy the model. We find that, for easy tasks, the optimal organization is a\nhomogeneous system composed of agents with the highest possible copy\npropensities. For difficult tasks, we find that diversity can prevent the\nsystem from being trapped in sub-optimal solutions. However, when the system\nsize is adjusted to maximize performance the homogeneous systems outperform the\nheterogeneous systems, i.e., for optimal performance, sameness should be\npreferred to diversity.", "subject": "Multiagent Systems (cs.MA)"}, {"idx": 55, "title": "A Unified Approach for Learning the Parameters of Sum-Product Networks", "abstract": "We present a unified approach for learning the parameters of Sum-Product\nnetworks (SPNs). We prove that any complete and decomposable SPN is equivalent\nto a mixture of trees where each tree corresponds to a product of univariate\ndistributions. Based on the mixture model perspective, we characterize the\nobjective function when learning SPNs based on the maximum likelihood\nestimation (MLE) principle and show that the optimization problem can be\nformulated as a signomial program. We construct two parameter learning\nalgorithms for SPNs by using sequential monomial approximations (SMA) and the\nconcave-convex procedure (CCCP), respectively. The two proposed methods\nnaturally admit multiplicative updates, hence effectively avoiding the\nprojection operation. With the help of the unified framework, we also show\nthat, in the case of SPNs, CCCP leads to the same algorithm as Expectation\nMaximization (EM) despite the fact that they are different in general.", "subject": "Machine Learning (cs.LG)"}, {"idx": 56, "title": "Cooperative Caching and Transmission Design in Cluster-Centric Small Cell Networks", "abstract": "Wireless content caching in small cell networks (SCNs) has recently been\nconsidered as an efficient way to reduce the traffic and the energy consumption\nof the backhaul in emerging heterogeneous cellular networks (HetNets). In this\npaper, we consider a cluster-centric SCN with combined design of cooperative\ncaching and transmission policy. Small base stations (SBSs) are grouped into\ndisjoint clusters, in which in-cluster cache space is utilized as an entity. We\npropose a combined caching scheme where part of the available cache space is\nreserved for caching the most popular content in every SBS, while the remaining\nis used for cooperatively caching different partitions of the less popular\ncontent in different SBSs, as a means to increase local content diversity.\nDepending on the availability and placement of the requested content,\ncoordinated multipoint (CoMP) technique with either joint transmission (JT) or\nparallel transmission (PT) is used to deliver content to the served user. Using\nPoisson point process (PPP) for the SBS location distribution and a hexagonal\ngrid model for the clusters, we provide analytical results on the successful\ncontent delivery probability of both transmission schemes for a user located at\nthe cluster center. Our analysis shows an inherent tradeoff between\ntransmission diversity and content diversity in our combined\ncaching-transmission design. We also study optimal cache space assignment for\ntwo objective functions: maximization of the cache service performance and the\nenergy efficiency. Simulation results show that the proposed scheme achieves\nperformance gain by leveraging cache-level and signal-level cooperation and\nadapting to the network environment and user QoS requirements.", "subject": "Networking and Internet Architecture (cs.NI)"}, {"idx": 57, "title": "The Design of a Community Science Cloud: The Open Science Data Cloud Perspective", "abstract": "In this paper we describe the design, and implementation of the Open Science\nData Cloud, or OSDC. The goal of the OSDC is to provide petabyte-scale data\ncloud infrastructure and related services for scientists working with large\nquantities of data. Currently, the OSDC consists of more than 2000 cores and 2\nPB of storage distributed across four data centers connected by 10G networks.\nWe discuss some of the lessons learned during the past three years of operation\nand describe the software stacks used in the OSDC. We also describe some of the\nresearch projects in biology, the earth sciences, and social sciences enabled\nby the OSDC.", "subject": "Computational Engineering, Finance, and Science (cs.CE)"}, {"idx": 58, "title": "Asymptotic Intrinsic Universality and Reprogrammability by Behavioural Emulation", "abstract": "We advance a Bayesian concept of 'intrinsic asymptotic universality' taking\nto its final conclusions previous conceptual and numerical work based upon a\nconcept of a reprogrammability test and an investigation of the complex\nqualitative behaviour of computer programs. Our method may quantify the trust\nand confidence of the computing capabilities of natural and classical systems,\nand quantify computers by their degree of reprogrammability. We test the method\nto provide evidence in favour of a conjecture concerning the computing\ncapabilities of Busy Beaver Turing machines as candidates for Turing\nuniversality. The method has recently been used to quantify the number of\n'intrinsically universal' cellular automata, with results that point towards\nthe pervasiveness of universality due to a widespread capacity for emulation.\nOur method represents an unconventional approach to the classical and seminal\nconcept of Turing universality, and it may be extended and applied in a broader\ncontext to natural computation, by (in something like the spirit of the Turing\ntest) observing the behaviour of a system under circumstances where formal\nproofs of universality are difficult, if not impossible to come by.", "subject": "Computational Complexity (cs.CC)"}, {"idx": 59, "title": "Generic Tracking Specifications Translation from Time Domain to Frequency Domain", "abstract": "In certain types of robust control techniques, it is common having to deal\nwith control problems where the specifications, described in the time domain,\nneed to be translated to the frequency domain. This usually happens in\ntechniques, such as Quantitative Feedback Theory, where the control problem is\ndeveloped in the frequency domain. Therefore, not only process plants and\ndisturbances should be specified in this domain, but also the limits and\nrestrictions initially imposed in time. The question is important if we\nconsider that any deviation in the parameters transfer from one domain to\nanother will decisively influence in the development of the problem and, above\nall, in the finally result expressed in temporal terms. The technique presented\nallows the translation of the upper frequency limit in generic tracking\nspecifications from time domain to frequency domain accurately. It will use\napproaches based on 2nd order systems or an envelope approach based on higher\norder systems.", "subject": "Systems and Control (eess.SY)"}, {"idx": 60, "title": "Internet of Things for Residential Areas: Toward Personalized Energy Management Using Big Data", "abstract": "Intelligent management of machines, particularly in a residence area, has\nbeen of interest for many years. However, such system design has always been\nlimited to simple control of machines from a local area or remotely from the\nInternet. In this report, for the first time, an intelligent system is\nproposed, where not only provides intelligent control ability of machines to\nuser, but also utilizes big data and optimization techniques to provide\npromotional offers to the user to optimize energy consumption of machines.\nSince a high traffic communication is involved among the machines and the\noptimization-big data core of system, the communication core of the proposed\nsystem is designed based on cloud, where many challenging issues such as\nspectrum assignment and resource management are involved. To deal with that,\nthe communication network in the home area network (HAN) is designed based on\nthe cognitive radio system, where a new spectrum assignment method based on the\nant colony optimization (ACO) algorithm is proposed to perform spectrum\nassignment to the machines in the HAN. Performance evaluation of the proposed\nspectrum assignment method shows its performance in fair spectrum assignment\namong machines.", "subject": "Networking and Internet Architecture (cs.NI)"}, {"idx": 61, "title": "Computational Soundness Results for Stateful Applied pi Calculus", "abstract": "In recent years, many researches have been done to establish symbolic models\nof stateful protocols. Two works among them, the SAPIC tool and StatVerif tool,\nprovide a high-level specification language and an automated analysis. Their\nlanguage, the stateful applied \u03c0-calculus, is extended from the applied\n\u03c0-calculus by defining explicit state constructs. Symbolic abstractions of\ncryptography used in it make the analysis amenable to automation. However, this\nmight overlook the attacks based on the algebraic properties of the\ncryptographic algorithms. In our paper, we establish the computational\nsoundness results for stateful applied \u03c0-calculus used in SAPIC tool and\nStatVerif tool.\n  In our approach, we build our results on the CoSP framework. For SAPIC, we\nembed the non-monotonic protocol states into the CoSP protocols, and prove that\nthe resulting CoSP protocols are efficient. Through the embedding, we provide\nthe computational soundness result for SAPIC (by Theorem 1). For StatVerif, we\nencode the StatVerif process into a subset of SAPIC process, and obtain the\ncomputational soundness result for StatVerif (by Theorem 2). Our encoding shows\nthe differences between the semantics of the two languages. Our work inherits\nthe modularity of CoSP, which allows for easily extending the proofs to\nspecific cryptographic primitives. Thus we establish a computationally sound\nautomated verification result for the input languages of SAPIC and StatVerif\nthat use public-key encryption and signatures (by Theorem 3).", "subject": "Cryptography and Security (cs.CR)"}, {"idx": 62, "title": "Benders Decomposition for the Design of a Hub and Shuttle Public Transit System", "abstract": "The BusPlus project aims at improving the off-peak hours public transit\nservice in Canberra, Australia. To address the difficulty of covering a large\ngeographic area, BusPlus proposes a hub and shuttle model consisting of a\ncombination of a few high-frequency bus routes between key hubs and a large\nnumber of shuttles that bring passengers from their origin to the closest hub\nand take them from their last bus stop to their destination. This paper focuses\non the design of bus network and proposes an efficient solving method to this\nmultimodal network design problem based on the Benders decomposition method.\nStarting from a MIP formulation of the problem, the paper presents a Benders\ndecomposition approach using dedicated solution techniques for solving\nindependent sub-problems, Pareto optimal cuts, cut bundling, and core point\nupdate. Computational results on real-world data from Canberra's public transit\nsystem justify the design choices and show that the approach outperforms the\nMIP formulation by two orders of magnitude. Moreover, the results show that the\nhub and shuttle model may decrease transit time by a factor of 2, while staying\nwithin the costs of the existing transit system.", "subject": "Artificial Intelligence (cs.AI)"}, {"idx": 63, "title": "Mutual Information and Diverse Decoding Improve Neural Machine Translation", "abstract": "Sequence-to-sequence neural translation models learn semantic and syntactic\nrelations between sentence pairs by optimizing the likelihood of the target\ngiven the source, i.e., $p(y|x)$, an objective that ignores other potentially\nuseful sources of information. We introduce an alternative objective function\nfor neural MT that maximizes the mutual information between the source and\ntarget sentences, modeling the bi-directional dependency of sources and\ntargets. We implement the model with a simple re-ranking method, and also\nintroduce a decoding algorithm that increases diversity in the N-best list\nproduced by the first pass. Applied to the WMT German/English and\nFrench/English tasks, the proposed models offers a consistent performance boost\non both standard LSTM and attention-based neural MT architectures.", "subject": "Computation and Language (cs.CL)"}, {"idx": 64, "title": "Wireless-Powered Cooperative Communications: Power-Splitting Relaying with Energy Accumulation", "abstract": "A harvest-use-store power splitting (PS) relaying strategy with distributed\nbeamforming is proposed for wirelesspowered multi-relay cooperative networks in\nthis paper. Different from the conventional battery-free PS relaying strategy,\nharvested energy is prioritized to power information relaying while the\nremainder is accumulated and stored for future usage with the help of a battery\nin the proposed strategy, which supports an efficient utilization of harvested\nenergy. However, PS affects throughput at subsequent time slots due to the\nbattery operations including the charging and discharging. To this end, PS and\nbattery operations are coupled with distributed beamforming. A throughput\noptimization problem to incorporate these coupled operations is formulated\nthough it is intractable. To address the intractability of the optimization,a\nlayered optimization method is proposed to achieve the optimal joint PS and\nbattery operation design with non-causal channel state information (CSI), in\nwhich the PS and the battery operation can be analyzed in a decomposed manner.\nThen, a general case with causal CSI is considered, where the proposed layered\noptimization method is extended by utilizing the statistical properties of CSI.\nTo reach a better tradeoff between performance and complexity, a greedy method\nthat requires no information about subsequent time slots is proposed.\nSimulation results reveal the upper and lower bound on performance of the\nproposed strategy, which are reached by the layered optimization method with\nnon-causal CSI and the greedy method, respectively. Moreover, the proposed\nstrategy outperforms the conventional PS-based relaying without energy\naccumulation and time switching-based relaying strategy.", "subject": "Information Theory (cs.IT)"}, {"idx": 65, "title": "On the Reducibility of Submodular Functions", "abstract": "The scalability of submodular optimization methods is critical for their\nusability in practice. In this paper, we study the reducibility of submodular\nfunctions, a property that enables us to reduce the solution space of\nsubmodular optimization problems without performance loss. We introduce the\nconcept of reducibility using marginal gains. Then we show that by adding\nperturbation, we can endow irreducible functions with reducibility, based on\nwhich we propose the perturbation-reduction optimization framework. Our\ntheoretical analysis proves that given the perturbation scales, the\nreducibility gain could be computed, and the performance loss has additive\nupper bounds. We further conduct empirical studies and the results demonstrate\nthat our proposed framework significantly accelerates existing optimization\nmethods for irreducible submodular functions with a cost of only small\nperformance losses.", "subject": "Machine Learning (cs.LG)"}, {"idx": 66, "title": "Automatic Detection and Decoding of Photogrammetric Coded Targets", "abstract": "Close-range Photogrammetry is widely used in many industries because of the\ncost effectiveness and efficiency of the technique. In this research, we\nintroduce an automated coded target detection method which can be used to\nenhance the efficiency of the Photogrammetry.", "subject": "Computer Vision and Pattern Recognition (cs.CV)"}, {"idx": 67, "title": "Distributed Storage in Mobile Wireless Networks with Device-to-Device Communication", "abstract": "We consider the use of distributed storage (DS) to reduce the communication\ncost of content delivery in wireless networks. Content is stored (cached) in a\nnumber of mobile devices using an erasure correcting code. Users retrieve\ncontent from other devices using device-to-device communication or from the\nbase station (BS), at the expense of higher communication cost. We address the\nrepair problem when a device storing data leaves the cell. We introduce a\nrepair scheduling where repair is performed periodically and derive analytical\nexpressions for the overall communication cost of content download and data\nrepair as a function of the repair interval. The derived expressions are then\nused to evaluate the communication cost entailed by DS using several erasure\ncorrecting codes. Our results show that DS can reduce the communication cost\nwith respect to the case where content is downloaded only from the BS, provided\nthat repairs are performed frequently enough. If devices storing content arrive\nto the cell, the communication cost using DS is further reduced and, for large\nenough arrival rate, it is always beneficial. Interestingly, we show that MDS\ncodes, which do not perform well for classical DS, can yield a low overall\ncommunication cost in wireless DS.", "subject": "Information Theory (cs.IT)"}, {"idx": 68, "title": "Multi-task CNN Model for Attribute Prediction", "abstract": "This paper proposes a joint multi-task learning algorithm to better predict\nattributes in images using deep convolutional neural networks (CNN). We\nconsider learning binary semantic attributes through a multi-task CNN model,\nwhere each CNN will predict one binary attribute. The multi-task learning\nallows CNN models to simultaneously share visual knowledge among different\nattribute categories. Each CNN will generate attribute-specific feature\nrepresentations, and then we apply multi-task learning on the features to\npredict their attributes. In our multi-task framework, we propose a method to\ndecompose the overall model's parameters into a latent task matrix and\ncombination matrix. Furthermore, under-sampled classifiers can leverage shared\nstatistics from other classifiers to improve their performance. Natural\ngrouping of attributes is applied such that attributes in the same group are\nencouraged to share more knowledge. Meanwhile, attributes in different groups\nwill generally compete with each other, and consequently share less knowledge.\nWe show the effectiveness of our method on two popular attribute datasets.", "subject": "Computer Vision and Pattern Recognition (cs.CV)"}, {"idx": 69, "title": "Fixed-point elimination in the intuitionistic propositional calculus", "abstract": "It is a consequence of existing literature that least and greatest\nfixed-points of monotone polynomials on Heyting algebras-that is, the algebraic\nmodels of the Intuitionistic Propositional Calculus-always exist, even when\nthese algebras are not complete as lattices. The reason is that these extremal\nfixed-points are definable by formulas of the IPC. Consequently, the\n$\u03bc$-calculus based on intuitionistic logic is trivial, every $\u03bc$-formula\nbeing equivalent to a fixed-point free formula. We give in this paper an\naxiomatization of least and greatest fixed-points of formulas, and an algorithm\nto compute a fixed-point free formula equivalent to a given $\u03bc$-formula. The\naxiomatization of the greatest fixed-point is simple. The axiomatization of the\nleast fixed-point is more complex, in particular every monotone formula\nconverges to its least fixed-point by Kleene's iteration in a finite number of\nsteps, but there is no uniform upper bound on the number of iterations. We\nextract, out of the algorithm, upper bounds for such n, depending on the size\nof the formula. For some formulas, we show that these upper bounds are\npolynomial and optimal.", "subject": "Logic in Computer Science (cs.LO)"}, {"idx": 70, "title": "Improving Bandwidth Efficiency of FBMC-OQAM Through Virtual Symbols", "abstract": "Filter bank multicarrier (FBMC) systems that are based on offset quadrature\namplitude modulation (OQAM), namely, FBMC-OQAM, have been criticized for their\ninefficiency in the use of spectral resources, because of the long ramp-up and\nramp-down tails at the beginning and the end of each data packet, respectively.\nWe propose a novel method for shortening these tails. By appending a set of\nvirtual (i.e., none data carrying) symbols to the beginning and the end of each\npacket, and clever selection of these symbols, we show that the ramp-up and\nrampdown tails in FMBC-OQAM can be suppressed to an extent that they deem as\nnegligible and thus may be ignored. This shortens the length of signal burst in\neach FBMC-OQAM packet, hence, improves on its bandwidth efficiency, viz., the\nsame data is transmitted over a shorter period of time. We develop an\noptimization method that allows computation of virtual symbols, for each data\npacket. Simulation results show that, compared to existing methods, the\nproposed tail-shortening approach leads to a superior out-of-band (OOB)\nemission performance and a much lower error vector magnitude (EVM) for the\ndemodulated symbols.", "subject": "Information Theory (cs.IT)"}, {"idx": 71, "title": "Kernel Sparse Subspace Clustering on Symmetric Positive Definite Manifolds", "abstract": "Sparse subspace clustering (SSC), as one of the most successful subspace\nclustering methods, has achieved notable clustering accuracy in computer vision\ntasks. However, SSC applies only to vector data in Euclidean space. As such,\nthere is still no satisfactory approach to solve subspace clustering by ${\\it\nself-expressive}$ principle for symmetric positive definite (SPD) matrices\nwhich is very useful in computer vision. In this paper, by embedding the SPD\nmatrices into a Reproducing Kernel Hilbert Space (RKHS), a kernel subspace\nclustering method is constructed on the SPD manifold through an appropriate\nLog-Euclidean kernel, termed as kernel sparse subspace clustering on the SPD\nRiemannian manifold (KSSCR). By exploiting the intrinsic Riemannian geometry\nwithin data, KSSCR can effectively characterize the geodesic distance between\nSPD matrices to uncover the underlying subspace structure. Experimental results\non two famous database demonstrate that the proposed method achieves better\nclustering results than the state-of-the-art approaches.", "subject": "Computer Vision and Pattern Recognition (cs.CV)"}, {"idx": 72, "title": "Energy Efficient Location and Activity-aware On-Demand Mobile Distributed Sensing Platform for Sensing as a Service in IoT Clouds", "abstract": "The Internet of Things (IoT) envisions billions of sensors deployed around us\nand connected to the Internet, where the mobile crowd sensing technologies are\nwidely used to collect data in different contexts of the IoT paradigm. Due to\nthe popularity of Big Data technologies, processing and storing large volumes\nof data has become easier than ever. However, large scale data management tasks\nstill require significant amounts of resources that can be expensive regardless\nof whether they are purchased or rented (e.g. pay-as-you-go infrastructure).\nFurther, not everyone is interested in such large scale data collection and\nanalysis. More importantly, not everyone has the financial and computational\nresources to deal with such large volumes of data. Therefore, a timely need\nexists for a cloud-integrated mobile crowd sensing platform that is capable of\ncapturing sensors data, on-demand, based on conditions enforced by the data\nconsumers. In this paper, we propose a context-aware, specifically, location\nand activity-aware mobile sensing platform called C-MOSDEN ( Context-aware\nMobile Sensor Data ENgine) for the IoT domain. We evaluated the proposed\nplatform using three real-world scenarios that highlight the importance of\n'selective sensing'. The computational effectiveness and efficiency of the\nproposed platform are investigated and is used to highlight the advantages of\ncontext-aware selective sensing.", "subject": "Networking and Internet Architecture (cs.NI)"}, {"idx": 73, "title": "Improper Gaussian Signaling in Full-Duplex Relay Channels with Residual Self-Interference", "abstract": "We study the potential employment of improper Gaussian signaling (IGS) in\nfull-duplex cooperative settings with residual self-interference (RSI). IGS is\nrecently shown to outperform traditional proper Gaussian signaling (PGS) in\nseveral interference-limited channel settings. In this work, IGS is employed in\nan attempt to alleviate the RSI adverse effect in full-duplex relaying (FDR).\nTo this end, we derive a tight upper bound expression for the end-to-end outage\nprobability in terms of the relay signal parameters represented in its power\nand circularity coefficient. We further show that the derived upper bound is\neither monotonic or unimodal in the relay's circularity coefficient. This\nresult allows for easily locating the global optimal point using known\nnumerical methods. Based on the analysis, IGS allows FDR systems to operate\neven with high RSI. It is shown that, while the communication totally fails\nwith PGS as the RSI increases, the IGS outage probability approaches a fixed\nvalue that depends on the channel statistics and target rate. The obtained\nresults show that IGS can leverage higher relay power budgets than PGS to\nimprove the performance, meanwhile it relieves its RSI impact via tuning the\nsignal impropriety.", "subject": "Information Theory (cs.IT)"}, {"idx": 74, "title": "Fitting Spectral Decay with the $k$-Support Norm", "abstract": "The spectral $k$-support norm enjoys good estimation properties in low rank\nmatrix learning problems, empirically outperforming the trace norm. Its unit\nball is the convex hull of rank $k$ matrices with unit Frobenius norm. In this\npaper we generalize the norm to the spectral $(k,p)$-support norm, whose\nadditional parameter $p$ can be used to tailor the norm to the decay of the\nspectrum of the underlying model. We characterize the unit ball and we\nexplicitly compute the norm. We further provide a conditional gradient method\nto solve regularization problems with the norm, and we derive an efficient\nalgorithm to compute the Euclidean projection on the unit ball in the case\n$p=\\infty$. In numerical experiments, we show that allowing $p$ to vary\nsignificantly improves performance over the spectral $k$-support norm on\nvarious matrix completion benchmarks, and better captures the spectral decay of\nthe underlying model.", "subject": "Machine Learning (cs.LG)"}, {"idx": 75, "title": "Interpolated-DFT-Based Fast and Accurate Amplitude and Phase Estimation for the Control of Power", "abstract": "The quality of energy produced in renewable energy systems has to be at the\nhigh level specified by respective standards and directives. The estimation\naccuracy of grid signal parameters is one of the most important factors\naffecting this quality. This paper presents a method for a very fast and\naccurate amplitude and phase grid signal estimation using the Fast Fourier\nTransform procedure and maximum decay sidelobes windows. The most important\nfeatures of the method are the elimination of the impact associated with the\nconjugate's component on the results and the straightforward implementation.\nMoreover, the measurement time is very short - even far less than one period of\nthe grid signal. The influence of harmonics on the results is reduced by using\na bandpass prefilter. Even using a 40 dB FIR prefilter for the grid signal with\nTHD = 38%, SNR = 53 dB and a 20-30% slow decay exponential drift the maximum\nerror of the amplitude estimation is approximately 1% and approximately 0.085\nrad of the phase estimation in a real-time DSP system for 512 samples. The\nerrors are smaller by several orders of magnitude for more accurate prefilters.", "subject": "Systems and Control (eess.SY)"}, {"idx": 76, "title": "Actin automata with memory", "abstract": "Actin is a globular protein which forms long polar filaments in eukaryotic.\nThe actin filaments play roles of cytoskeleton, motility units , information\nprocessing and learning. We model actin filament as a double chain of finite\nstate machines, nodes, which take states `0' and `1'. The states are\nabstractions of absence and presence of a sub-threshold charge on an actin\nunits corresponding to the nodes. All nodes update their state in parallel in\ndiscrete time. A node updates its current state depending on states of two\nclosest neighbours in the node chain and two closest neighbours in the\ncomplementary chain. Previous models of actin automata considered momentary\nstate transitions of nodes. We enrich the actin automata model by assuming that\nstates of nodes depends not only on the current states of neighbouring node but\nalso on their past states. Thus, we assess the effect of memory of past states\non the dynamics of acting automata. We demonstrate in computational experiments\nthat memory slows down propagation of perturbations, decrease entropy of\nspace-time patterns generated, transforms travelling localisations to\nstationary oscillators, and stationary oscillations to still patterns.", "subject": "Emerging Technologies (cs.ET)"}, {"idx": 77, "title": "The discretised lognormal and hooked power law distributions for complete citation data: Best options for modelling and regression", "abstract": "Identifying the statistical distribution that best fits citation data is\nimportant to allow robust and powerful quantitative analyses. Whilst previous\nstudies have suggested that both the hooked power law and discretised lognormal\ndistributions fit better than the power law and negative binomial\ndistributions, no comparisons so far have covered all articles within a\ndiscipline, including those that are uncited. Based on an analysis of 26\ndifferent Scopus subject areas in seven different years, this article reports\ncomparisons of the discretised lognormal and the hooked power law with citation\ndata, adding 1 to citation counts in order to include zeros. The hooked power\nlaw fits better in two thirds of the subject/year combinations tested for\njournal articles that are at least three years old, including most medical,\nlife and natural sciences, and for virtually all subject areas for younger\narticles. Conversely, the discretised lognormal tends to fit best for arts,\nhumanities, social science and engineering fields. The difference between the\nfits of the distributions is mostly small, however, and so either could\nreasonably be used for modelling citation data. For regression analyses,\nhowever, the best option is to use ordinary least squares regression applied to\nthe natural logarithm of citation counts plus one, especially for sets of\nyounger articles, because of the increased precision of the parameters.", "subject": "Digital Libraries (cs.DL)"}, {"idx": 78, "title": "Motivating Time-Inconsistent Agents: A Computational Approach", "abstract": "In this paper we investigate the computational complexity of motivating\ntime-inconsistent agents to complete long term projects. We resort to an\nelegant graph-theoretic model, introduced by Kleinberg and Oren, which consists\nof a task graph $G$ with $n$ vertices, including a source $s$ and target $t$,\nand an agent that incrementally constructs a path from $s$ to $t$ in order to\ncollect rewards. The twist is that the agent is present-biased and discounts\nfuture costs and rewards by a factor $\u03b2\\in [0,1]$. Our design objective is\nto ensure that the agent reaches $t$ i.e.\\ completes the project, for as little\nreward as possible. Such graphs are called motivating. We consider two\nstrategies. First, we place a single reward $r$ at $t$ and try to guide the\nagent by removing edges from $G$. We prove that deciding the existence of such\nmotivating subgraphs is NP-complete if $r$ is fixed. More importantly, we\ngeneralize our reduction to a hardness of approximation result for computing\nthe minimum $r$ that admits a motivating subgraph. In particular, we show that\nno polynomial-time approximation to within a ratio of $\\sqrt{n}/4$ or less is\npossible, unless ${\\rm P}={\\rm NP}$. Furthermore, we develop a\n$(1+\\sqrt{n})$-approximation algorithm and thus settle the approximability of\ncomputing motivating subgraphs. Secondly, we study motivating reward\nconfigurations, where non-negative rewards $r(v)$ may be placed on arbitrary\nvertices $v$ of $G$. The agent only receives the rewards of visited vertices.\nAgain we give an NP-completeness result for deciding the existence of a\nmotivating reward configuration within a fixed budget $b$. This result even\nholds if $b=0$, which in turn implies that no efficient approximation of a\nminimum $b$ within a ration grater or equal to $1$ is possible, unless ${\\rm\nP}={\\rm NP}$.", "subject": "Computational Complexity (cs.CC)"}, {"idx": 79, "title": "Data Portraits and Intermediary Topics: Encouraging Exploration of Politically Diverse Profiles", "abstract": "In micro-blogging platforms, people connect and interact with others.\nHowever, due to cognitive biases, they tend to interact with like-minded people\nand read agreeable information only. Many efforts to make people connect with\nthose who think differently have not worked well. In this paper, we\nhypothesize, first, that previous approaches have not worked because they have\nbeen direct -- they have tried to explicitly connect people with those having\nopposing views on sensitive issues. Second, that neither recommendation or\npresentation of information by themselves are enough to encourage behavioral\nchange. We propose a platform that mixes a recommender algorithm and a\nvisualization-based user interface to explore recommendations. It recommends\npolitically diverse profiles in terms of distance of latent topics, and\ndisplays those recommendations in a visual representation of each user's\npersonal content. We performed an \"in the wild\" evaluation of this platform,\nand found that people explored more recommendations when using a biased\nalgorithm instead of ours. In line with our hypothesis, we also found that the\nmixture of our recommender algorithm and our user interface, allowed\npolitically interested users to exhibit an unbiased exploration of the\nrecommended profiles. Finally, our results contribute insights in two aspects:\nfirst, which individual differences are important when designing platforms\naimed at behavioral change; and second, which algorithms and user interfaces\nshould be mixed to help users avoid cognitive mechanisms that lead to biased\nbehavior.", "subject": "Human-Computer Interaction (cs.HC)"}, {"idx": 80, "title": "SDDs are Exponentially More Succinct than OBDDs", "abstract": "Introduced by Darwiche (2011), sentential decision diagrams (SDDs) are\nessentially as tractable as ordered binary decision diagrams (OBDDs), but tend\nto be more succinct in practice. This makes SDDs a prominent representation\nlanguage, with many applications in artificial intelligence and knowledge\ncompilation. We prove that SDDs are more succinct than OBDDs also in theory, by\nconstructing a family of boolean functions where each member has polynomial SDD\nsize but exponential OBDD size. This exponential separation improves a\nquasipolynomial separation recently established by Razgon (2013), and settles\nan open problem in knowledge compilation.", "subject": "Logic in Computer Science (cs.LO)"}, {"idx": 81, "title": "Why Just Boogie? Translating Between Intermediate Verification Languages", "abstract": "The verification systems Boogie and Why3 use their respective intermediate\nlanguages to generate verification conditions from high-level programs. Since\nthe two systems support different back-end provers (such as Z3 and Alt-Ergo)\nand are used to encode different high-level languages (such as C# and Java),\nbeing able to translate between their intermediate languages would provide a\nway to reuse one system's features to verify programs meant for the other. This\npaper describes a translation of Boogie into WhyML (Why3's intermediate\nlanguage) that preserves semantics, verifiability, and program structure to a\nlarge degree. We implemented the translation as a tool and applied it to 194\nBoogie-verified programs of various sources and sizes; Why3 verified 83% of the\ntranslated programs with the same outcome as Boogie. These results indicate\nthat the translation is often effective and practically applicable.", "subject": "Logic in Computer Science (cs.LO)"}, {"idx": 82, "title": "ResFi: A Secure Framework for Self Organized Radio Resource Management in Residential WiFi Networks", "abstract": "In dense deployments of residential WiFi networks individual users suffer\nperformance degradation due to both contention and interference. While Radio\nResource Management (RRM) is known to mitigate this effects its application in\nresidential WiFi networks being by nature unplanned and individually managed\ncreates a big challenge. We propose ResFi - a framework supporting creation of\nRRM functionality in legacy deployments. The radio interfaces are used for\nefficient discovery of adjacent APs and as a side-channel to establish a secure\ncommunication among the individual Access Point Management Applications within\na neighborhood over the wired Internet backbone. We have implemented a\nprototype of ResFi and studied its performance in our testbed. As a showcase we\nhave implemented various RRM applications among others a distributed channel\nassignment algorithm using ResFi. ResFi is provided to the community as open\nsource.", "subject": "Networking and Internet Architecture (cs.NI)"}, {"idx": 83, "title": "Ideal Databases", "abstract": "From algebraic geometry perspective database relations are succinctly defined\nas Finite Varieties. After establishing basic framework, we give analytic proof\nof Heath theorem from Database Dependency theory. Next, we leverage\nAlgebra/Geometry dictionary and focus on algebraic counterparts of finite\nvarieties, polynomial ideals. It is well known that intersection and sum of\nideals are lattice operations. We generalize this fact to ideals from different\nrings, therefore establishing that algebra of ideals is Relational Lattice. The\nfinal stop is casting the framework into Linear Algebra, and traversing to\nQuantum Theory.", "subject": "Databases (cs.DB)"}, {"idx": 84, "title": "The Social Medium Selection Game", "abstract": "We consider in this paper competition of content creators in routing their\ncontent through various media. The routing decisions may correspond to the\nselection of a social network (e.g. twitter versus facebook or linkedin) or of\na group within a given social network. The utility for a player to send its\ncontent to some medium is given as the difference between the dissemination\nutility at this medium and some transmission cost. We model this game as a\ncongestion game and compute the pure potential of the game. In contrast to the\ncontinuous case, we show that there may be various equilibria. We show that the\npotential is M-concave which allows us to characterize the equilibria and to\npropose an algorithm for computing it. We then give a learning mechanism which\nallow us to give an efficient algorithm to determine an equilibrium. We finally\ndetermine the asymptotic form of the equilibrium and discuss the implications\non the social medium selection problem.", "subject": "Computer Science and Game Theory (cs.GT)"}, {"idx": 85, "title": "Programming in logic without logic programming", "abstract": "In previous work, we proposed a logic-based framework in which computation is\nthe execution of actions in an attempt to make reactive rules of the form if\nantecedent then consequent true in a canonical model of a logic program\ndetermined by an initial state, sequence of events, and the resulting sequence\nof subsequent states. In this model-theoretic semantics, reactive rules are the\ndriving force, and logic programs play only a supporting role.\n  In the canonical model, states, actions and other events are represented with\ntimestamps. But in the operational semantics, for the sake of efficiency,\ntimestamps are omitted and only the current state is maintained. State\ntransitions are performed reactively by executing actions to make the\nconsequents of rules true whenever the antecedents become true. This\noperational semantics is sound, but incomplete. It cannot make reactive rules\ntrue by preventing their antecedents from becoming true, or by proactively\nmaking their consequents true before their antecedents become true.\n  In this paper, we characterize the notion of reactive model, and prove that\nthe operational semantics can generate all and only such models. In order to\nfocus on the main issues, we omit the logic programming component of the\nframework.", "subject": "Artificial Intelligence (cs.AI)"}, {"idx": 86, "title": "HISTORY: An Efficient and Robust Algorithm for Noisy 1-bit Compressed Sensing", "abstract": "We consider the problem of sparse signal recovery from 1-bit measurements.\nDue to the noise present in the acquisition and transmission process, some\nquantized bits may be flipped to their opposite states. These sign flips may\nresult in severe performance degradation. In this study, a novel algorithm,\ntermed HISTORY, is proposed. It consists of Hamming support detection and\ncoefficients recovery. The HISTORY algorithm has high recovery accuracy and is\nrobust to strong measurement noise. Numerical results are provided to\ndemonstrate the effectiveness and superiority of the proposed algorithm.", "subject": "Information Theory (cs.IT)"}, {"idx": 87, "title": "Crowds for Clouds: Recent Trends in Humanities Research Infrastructures", "abstract": "Humanities have convincingly argued that they need transnational research\nopportunities and through the digital transformation of their disciplines also\nhave the means to proceed with it on an up to now unknown scale. The digital\ntransformation of research and its resources means that many of the artifacts,\ndocuments, materials, etc. that interest humanities research can now be\ncombined in new and innovative ways. Due to the digital transformations, (big)\ndata and information have become central to the study of culture and society.\nHumanities research infrastructures manage, organise and distribute this kind\nof information and many more data objects as they becomes relevant for social\nand cultural research.", "subject": "Other Computer Science (cs.OH)"}, {"idx": 88, "title": "Approximate Message Passing with Nearest Neighbor Sparsity Pattern Learning", "abstract": "We consider the problem of recovering clustered sparse signals with no prior\nknowledge of the sparsity pattern. Beyond simple sparsity, signals of interest\noften exhibits an underlying sparsity pattern which, if leveraged, can improve\nthe reconstruction performance. However, the sparsity pattern is usually\nunknown a priori. Inspired by the idea of k-nearest neighbor (k-NN) algorithm,\nwe propose an efficient algorithm termed approximate message passing with\nnearest neighbor sparsity pattern learning (AMP-NNSPL), which learns the\nsparsity pattern adaptively. AMP-NNSPL specifies a flexible spike and slab\nprior on the unknown signal and, after each AMP iteration, sets the sparse\nratios as the average of the nearest neighbor estimates via expectation\nmaximization (EM). Experimental results on both synthetic and real data\ndemonstrate the superiority of our proposed algorithm both in terms of\nreconstruction performance and computational complexity.", "subject": "Information Theory (cs.IT)"}, {"idx": 89, "title": "NFL Play Prediction", "abstract": "Based on NFL game data we try to predict the outcome of a play in multiple\ndifferent ways. An application of this is the following: by plugging in various\nplay options one could determine the best play for a given situation in real\ntime. While the outcome of a play can be described in many ways we had the most\npromising results with a newly defined measure that we call \"progress\". We see\nthis work as a first step to include predictive analysis into NFL playcalling.", "subject": "Machine Learning (cs.LG)"}, {"idx": 90, "title": "A Single-Assignment Translation for Annotated Programs", "abstract": "We present a translation of While programs annotated with loop invariants\ninto a dynamic single-assignment language with a dedicated iterating construct.\nWe prove that the translation is sound and complete. This is a companion report\nto our paper Formalizing Single-assignment Program Verification: an\nAdaptation-complete Approach [6].", "subject": "Logic in Computer Science (cs.LO)"}, {"idx": 91, "title": "Robust Non-linear Regression: A Greedy Approach Employing Kernels with Application to Image Denoising", "abstract": "We consider the task of robust non-linear regression in the presence of both\ninlier noise and outliers. Assuming that the unknown non-linear function\nbelongs to a Reproducing Kernel Hilbert Space (RKHS), our goal is to estimate\nthe set of the associated unknown parameters. Due to the presence of outliers,\ncommon techniques such as the Kernel Ridge Regression (KRR) or the Support\nVector Regression (SVR) turn out to be inadequate. Instead, we employ sparse\nmodeling arguments to explicitly model and estimate the outliers, adopting a\ngreedy approach. The proposed robust scheme, i.e., Kernel Greedy Algorithm for\nRobust Denoising (KGARD), is inspired by the classical Orthogonal Matching\nPursuit (OMP) algorithm. Specifically, the proposed method alternates between a\nKRR task and an OMP-like selection step. Theoretical results concerning the\nidentification of the outliers are provided. Moreover, KGARD is compared\nagainst other cutting edge methods, where its performance is evaluated via a\nset of experiments with various types of noise. Finally, the proposed robust\nestimation framework is applied to the task of image denoising, and its\nenhanced performance in the presence of outliers is demonstrated.", "subject": "Machine Learning (cs.LG)"}, {"idx": 92, "title": "Multimodal Classification of Events in Social Media", "abstract": "A large amount of social media hosted on platforms like Flickr and Instagram\nis related to social events. The task of social event classification refers to\nthe distinction of event and non-event-related content as well as the\nclassification of event types (e.g. sports events, concerts, etc.). In this\npaper, we provide an extensive study of textual, visual, as well as multimodal\nrepresentations for social event classification. We investigate strengths and\nweaknesses of the modalities and study synergy effects between the modalities.\nExperimental results obtained with our multimodal representation outperform\nstate-of-the-art methods and provide a new baseline for future research.", "subject": "Computer Vision and Pattern Recognition (cs.CV)"}, {"idx": 93, "title": "Scheduling and Power Allocation to Optimize Service and Queue-Waiting Times in Cognitive Radio Uplinks", "abstract": "In this report, we study the packet delay as a QoS metric in CR systems. The\npacket delay includes the queue waiting time and the service time. In this\nwork, we study the effect of both the scheduling and the power allocation\nalgorithms on the delay performance of the SUs.\n  To study the delay due to the service time we study a multichannel system\nwhere the channels are sensed sequentially, we study the tradeoff between\nthroughput and delay. The problem is formulated as an optimal stopping rule\nproblem where there is a tradeoff between the service time and the throughput.\nThis tradeoff results from skipping low-quality channels to seek the\npossibility of finding high-quality ones in the future at the expense of a\nhigher probability of being blocked from transmission since these future\nchannels might be busy.\n  On the other hand, the queue waiting time is studied by considering a\nmulti-user single channel system. Specifically, we study the effect of\nscheduling and power allocation on the delay performance of all SUs in the\nsystem. We propose a delay optimal algorithm that protects the PUs from harmful\ninterference and provides the required delay guarantees to users. Conventional\nscheduling algorithms do not provide such guarantees if the interference\nchannels are heterogeneous. This is because they are developed for conventional\nnon-CR wireless systems that neglect interference since channels are\northogonal.\n  Finally, we present two potential extensions to these studied problems.", "subject": "Information Theory (cs.IT)"}, {"idx": 94, "title": "Coresets and Sketches", "abstract": "Geometric data summarization has become an essential tool in both geometric\napproximation algorithms and where geometry intersects with big data problems.\nIn linear or near-linear time large data sets can be compressed into a summary,\nand then more intricate algorithms can be run on the summaries whose results\napproximate those of the full data set. Coresets and sketches are the two most\nimportant classes of these summaries. We survey five types of coresets and\nsketches: shape-fitting, density estimation, high-dimensional vectors,\nhigh-dimensional point sets / matrices, and clustering.", "subject": "Computational Geometry (cs.CG)"}, {"idx": 95, "title": "Distant IE by Bootstrapping Using Lists and Document Structure", "abstract": "Distant labeling for information extraction (IE) suffers from noisy training\ndata. We describe a way of reducing the noise associated with distant IE by\nidentifying coupling constraints between potential instance labels. As one\nexample of coupling, items in a list are likely to have the same label. A\nsecond example of coupling comes from analysis of document structure: in some\ncorpora, sections can be identified such that items in the same section are\nlikely to have the same label. Such sections do not exist in all corpora, but\nwe show that augmenting a large corpus with coupling constraints from even a\nsmall, well-structured corpus can improve performance substantially, doubling\nF1 on one task.", "subject": "Computation and Language (cs.CL)"}, {"idx": 96, "title": "Scalable Models for Computing Hierarchies in Information Networks", "abstract": "Information hierarchies are organizational structures that often used to\norganize and present large and complex information as well as provide a\nmechanism for effective human navigation. Fortunately, many statistical and\ncomputational models exist that automatically generate hierarchies; however,\nthe existing approaches do not consider linkages in information {\\em networks}\nthat are increasingly common in real-world scenarios. Current approaches also\ntend to present topics as an abstract probably distribution over words, etc\nrather than as tangible nodes from the original network. Furthermore, the\nstatistical techniques present in many previous works are not yet capable of\nprocessing data at Web-scale. In this paper we present the Hierarchical\nDocument Topic Model (HDTM), which uses a distributed vertex-programming\nprocess to calculate a nonparametric Bayesian generative model. Experiments on\nthree medium size data sets and the entire Wikipedia dataset show that HDTM can\ninfer accurate hierarchies even over large information networks.", "subject": "Artificial Intelligence (cs.AI)"}, {"idx": 97, "title": "Approximating the Distribution of the Median and other Robust Estimators on Uncertain Data", "abstract": "Robust estimators, like the median of a point set, are important for data\nanalysis in the presence of outliers. We study robust estimators for\nlocationally uncertain points with discrete distributions. That is, each point\nin a data set has a discrete probability distribution describing its location.\nThe probabilistic nature of uncertain data makes it challenging to compute such\nestimators, since the true value of the estimator is now described by a\ndistribution rather than a single point. We show how to construct and estimate\nthe distribution of the median of a point set. Building the approximate support\nof the distribution takes near-linear time, and assigning probability to that\nsupport takes quadratic time. We also develop a general approximation technique\nfor distributions of robust estimators with respect to ranges with bounded VC\ndimension. This includes the geometric median for high dimensions and the\nSiegel estimator for linear regression.", "subject": "Discrete Mathematics (cs.DM)"}, {"idx": 98, "title": "Hybrid Approach for Single Text Document Summarization using Statistical and Sentiment Features", "abstract": "Summarization is a way to represent same information in concise way with\nequal sense. This can be categorized in two type Abstractive and Extractive\ntype. Our work is focused around Extractive summarization. A generic approach\nto extractive summarization is to consider sentence as an entity, score each\nsentence based on some indicative features to ascertain the quality of sentence\nfor inclusion in summary. Sort the sentences on the score and consider top n\nsentences for summarization. Mostly statistical features have been used for\nscoring the sentences. We are proposing a hybrid model for a single text\ndocument summarization. This hybrid model is an extraction based approach,\nwhich is combination of Statistical and semantic technique. The hybrid model\ndepends on the linear combination of statistical measures : sentence position,\nTF-IDF, Aggregate similarity, centroid, and semantic measure. Our idea to\ninclude sentiment analysis for salient sentence extraction is derived from the\nconcept that emotion plays an important role in communication to effectively\nconvey any message hence, it can play a vital role in text document\nsummarization. For comparison we have generated five system summaries Proposed\nWork, MEAD system, Microsoft system, OPINOSIS system, and Human generated\nsummary, and evaluation is done using ROUGE score.", "subject": "Information Retrieval (cs.IR)"}, {"idx": 99, "title": "Artwork creation by a cognitive architecture integrating computational creativity and dual process approaches", "abstract": "The paper proposes a novel cognitive architecture (CA) for computational\ncreativity based on the Psi model and on the mechanisms inspired by dual\nprocess theories of reasoning and rationality. In recent years, many cognitive\nmodels have focused on dual process theories to better describe and implement\ncomplex cognitive skills in artificial agents, but creativity has been\napproached only at a descriptive level. In previous works we have described\nvarious modules of the cognitive architecture that allows a robot to execute\ncreative paintings. By means of dual process theories we refine some relevant\nmechanisms to obtain artworks, and in particular we explain details about the\nresolution level of the CA dealing with different strategies of access to the\nLong Term Memory (LTM) and managing the interaction between S1 and S2 processes\nof the dual process theory. The creative process involves both divergent and\nconvergent processes in either implicit or explicit manner. This leads to four\nactivities (exploratory, reflective, tacit, and analytic) that, triggered by\nurges and motivations, generate creative acts. These creative acts exploit both\nthe LTM and the WM in order to make novel substitutions to a perceived image by\nproperly mixing parts of pictures coming from different domains. The paper\nhighlights the role of the interaction between S1 and S2 processes, modulated\nby the resolution level, which focuses the attention of the creative agent by\nbroadening or narrowing the exploration of novel solutions, or even drawing the\nsolution from a set of already made associations. An example of artificial\npainter is described in some experimentations by using a robotic platform.", "subject": "Artificial Intelligence (cs.AI)"}, {"idx": 100, "title": "Modeling and Simulation of Molecular Communication Systems with a Reversible Adsorption Receiver", "abstract": "In this paper, we present an analytical model for the diffusive molecular\ncommunication (MC) system with a reversible adsorption receiver in a fluid\nenvironment. The widely used concentration shift keying (CSK) is considered for\nmodulation. The time-varying spatial distribution of the information molecules\nunder the reversible adsorption and desorption reaction at the surface of a\nreceiver is analytically characterized. Based on the spatial distribution, we\nderive the net number of newly-adsorbed information molecules expected in any\ntime duration. We further derive the number of newly-adsorbed molecules\nexpected at the steady state to demonstrate the equilibrium concentration.\nGiven the number of newly-adsorbed information molecules, the bit error\nprobability of the proposed MC system is analytically approximated.\nImportantly, we present a simulation framework for the proposed model that\naccounts for the diffusion and reversible reaction. Simulation results show the\naccuracy of our derived expressions, and demonstrate the positive effect of the\nadsorption rate and the negative effect of the desorption rate on the error\nprobability of reversible adsorption receiver with last transmit bit-1.\nMoreover, our analytical results simplify to the special cases of a full\nadsorption receiver and a partial adsorption receiver, both of which do not\ninclude desorption.", "subject": "Emerging Technologies (cs.ET)"}, {"idx": 101, "title": "Spectral and Modular Analysis of #P Problems", "abstract": "We present various analytic and number theoretic results concerning the #SAT\nproblem as reflected when reduced into a #PART problem. As an application we\npropose a heuristic to probabilistically estimate the solution of #SAT\nproblems.", "subject": "Computational Complexity (cs.CC)"}, {"idx": 102, "title": "Weakly-supervised Disentangling with Recurrent Transformations for 3D View Synthesis", "abstract": "An important problem for both graphics and vision is to synthesize novel\nviews of a 3D object from a single image. This is particularly challenging due\nto the partial observability inherent in projecting a 3D object onto the image\nspace, and the ill-posedness of inferring object shape and pose. However, we\ncan train a neural network to address the problem if we restrict our attention\nto specific object categories (in our case faces and chairs) for which we can\ngather ample training data. In this paper, we propose a novel recurrent\nconvolutional encoder-decoder network that is trained end-to-end on the task of\nrendering rotated objects starting from a single image. The recurrent structure\nallows our model to capture long-term dependencies along a sequence of\ntransformations. We demonstrate the quality of its predictions for human faces\non the Multi-PIE dataset and for a dataset of 3D chair models, and also show\nits ability to disentangle latent factors of variation (e.g., identity and\npose) without using full supervision.", "subject": "Machine Learning (cs.LG)"}, {"idx": 103, "title": "A Survey of RDF Data Management Systems", "abstract": "RDF is increasingly being used to encode data for the semantic web and for\ndata exchange. There have been a large number of works that address RDF data\nmanagement. In this paper we provide an overview of these works.", "subject": "Databases (cs.DB)"}, {"idx": 104, "title": "Multi-Source Neural Translation", "abstract": "We build a multi-source machine translation model and train it to maximize\nthe probability of a target English string given French and German sources.\nUsing the neural encoder-decoder framework, we explore several combination\nmethods and report up to +4.8 Bleu increases on top of a very strong\nattention-based neural translation model.", "subject": "Computation and Language (cs.CL)"}, {"idx": 105, "title": "Almost Continuous Transformations of Software and Higher-order Dataflow Programming", "abstract": "We consider two classes of stream-based computations which admit taking\nlinear combinations of execution runs: probabilistic sampling and generalized\nanimation. The dataflow architecture is a natural platform for programming with\nstreams. The presence of linear combinations allows us to introduce the notion\nof almost continuous transformation of dataflow graphs. We introduce a new\napproach to higher-order dataflow programming: a dynamic dataflow program is a\nstream of dataflow graphs evolving by almost continuous transformations. A\ndynamic dataflow program would typically run while it evolves. We introduce\nFluid, an experimental open source system for programming with dataflow graphs\nand almost continuous transformations.", "subject": "Programming Languages (cs.PL)"}, {"idx": 106, "title": "Optimum Transmission Policies for Energy Harvesting Sensor Networks Powered By a Mobile Control Center", "abstract": "Wireless energy transfer, namely RF-based energy harvesting, is a potential\nway to prolong the lifetime of energy-constrained devices, especially in\nwireless sensor networks. However, due to huge propagation attenuation, its\nenergy efficiency is regarded as the biggest bottleneck to widely applications.\nIt is critical to find appropriate transmission policies to improve the global\nenergy efficiency in this kind of systems. To this end, this paper focuses on\nthe sensor networks scenario, where a mobile control center powers the sensors\nby RF signal and also collects information from them. Two related schemes,\ncalled as harvest-and-use scheme and harvest-store-use scheme, are\ninvestigated, respectively. In harvest-and-use scheme, as a benchmark, both\nconstant and adaptive transmission modes from sensors are discussed. To\nharvest-store-use scheme, we propose a new concept, the best opportunity for\nwireless energy transfer, and use it to derive an explicit closed-form\nexpression of optimal transmission policy. It is shown by simulation that a\nconsiderable improvement in terms of energy efficiency can be obtained with the\nhelp of the transmission policies developed in this paper. Furthermore, the\ntransmission policies is also discussed under the constraint of fixed\ninformation rate. The minimal required power, the performance loss from the new\nconstraint as well as the effect of fading are then presented.", "subject": "Information Theory (cs.IT)"}, {"idx": 107, "title": "Matrix Variate RBM and Its Applications", "abstract": "Restricted Boltzmann Machine (RBM) is an importan- t generative model\nmodeling vectorial data. While applying an RBM in practice to images, the data\nhave to be vec- torized. This results in high-dimensional data and valu- able\nspatial information has got lost in vectorization. In this paper, a\nMatrix-Variate Restricted Boltzmann Machine (MVRBM) model is proposed by\ngeneralizing the classic RBM to explicitly model matrix data. In the new RBM\nmodel, both input and hidden variables are in matrix forms which are connected\nby bilinear transforms. The MVRBM has much less model parameters, resulting in\na faster train- ing algorithm while retaining comparable performance as the\nclassic RBM. The advantages of the MVRBM have been demonstrated on two\nreal-world applications: Image super- resolution and handwritten digit\nrecognition.", "subject": "Computer Vision and Pattern Recognition (cs.CV)"}, {"idx": 108, "title": "Low-Rank Representation over the Manifold of Curves", "abstract": "In machine learning it is common to interpret each data point as a vector in\nEuclidean space. However the data may actually be functional i.e.\\ each data\npoint is a function of some variable such as time and the function is\ndiscretely sampled. The naive treatment of functional data as traditional\nmultivariate data can lead to poor performance since the algorithms are\nignoring the correlation in the curvature of each function. In this paper we\npropose a method to analyse subspace structure of the functional data by using\nthe state of the art Low-Rank Representation (LRR). Experimental evaluation on\nsynthetic and real data reveals that this method massively outperforms\nconventional LRR in tasks concerning functional data.", "subject": "Computer Vision and Pattern Recognition (cs.CV)"}, {"idx": 109, "title": "Resource Sharing for Multi-Tenant NoSQL Data Store in Cloud", "abstract": "Multi-tenancy hosting of users in cloud NoSQL data stores is favored by cloud\nproviders because it enables resource sharing at low operating cost.\nMulti-tenancy takes several forms depending on whether the back-end file system\nis a local file system (LFS) or a parallel file system (PFS), and on whether\ntenants are independent or share data across tenants. In this thesis I focus on\nand propose solutions to two cases: independent data-local file system, and\nshared data-parallel file system.\n  In the independent data-local file system case, resource contention occurs\nunder certain conditions in Cassandra and HBase, two state-of-the-art NoSQL\nstores, causing performance degradation for one tenant by another. We\ninvestigate the interference and propose two approaches. The first provides a\nscheduling scheme that can approximate resource consumption, adapt to workload\ndynamics and work in a distributed fashion. The second introduces a\nworkload-aware resource reservation approach to prevent interference. The\napproach relies on a performance model obtained offline and plans the\nreservation according to different workload resource demands. Results show the\napproaches together can prevent interference and adapt to dynamic workloads\nunder multi-tenancy.\n  In the shared data-parallel file system case, it has been shown that running\na distributed NoSQL store over PFS for shared data across tenants is not cost\neffective. Overheads are introduced due to the unawareness of the NoSQL store\nof PFS. This dissertation targets the key-value store (KVS), a specific form of\nNoSQL stores, and proposes a lightweight KVS over a parallel file system to\nimprove efficiency. The solution is built on an embedded KVS for high\nperformance but uses novel data structures to support concurrent writes.\nResults show the proposed system outperforms Cassandra and Voldemort in several\ndifferent workloads.", "subject": "Distributed, Parallel, and Cluster Computing (cs.DC)"}, {"idx": 110, "title": "Brain4Cars: Car That Knows Before You Do via Sensory-Fusion Deep Learning Architecture", "abstract": "Advanced Driver Assistance Systems (ADAS) have made driving safer over the\nlast decade. They prepare vehicles for unsafe road conditions and alert drivers\nif they perform a dangerous maneuver. However, many accidents are unavoidable\nbecause by the time drivers are alerted, it is already too late. Anticipating\nmaneuvers beforehand can alert drivers before they perform the maneuver and\nalso give ADAS more time to avoid or prepare for the danger.\n  In this work we propose a vehicular sensor-rich platform and learning\nalgorithms for maneuver anticipation. For this purpose we equip a car with\ncameras, Global Positioning System (GPS), and a computing device to capture the\ndriving context from both inside and outside of the car. In order to anticipate\nmaneuvers, we propose a sensory-fusion deep learning architecture which jointly\nlearns to anticipate and fuse multiple sensory streams. Our architecture\nconsists of Recurrent Neural Networks (RNNs) that use Long Short-Term Memory\n(LSTM) units to capture long temporal dependencies. We propose a novel training\nprocedure which allows the network to predict the future given only a partial\ntemporal context. We introduce a diverse data set with 1180 miles of natural\nfreeway and city driving, and show that we can anticipate maneuvers 3.5 seconds\nbefore they occur in real-time with a precision and recall of 90.5\\% and 87.4\\%\nrespectively.", "subject": "Robotics (cs.RO)"}, {"idx": 111, "title": "Learning Preferences for Manipulation Tasks from Online Coactive Feedback", "abstract": "We consider the problem of learning preferences over trajectories for mobile\nmanipulators such as personal robots and assembly line robots. The preferences\nwe learn are more intricate than simple geometric constraints on trajectories;\nthey are rather governed by the surrounding context of various objects and\nhuman interactions in the environment. We propose a coactive online learning\nframework for teaching preferences in contextually rich environments. The key\nnovelty of our approach lies in the type of feedback expected from the user:\nthe human user does not need to demonstrate optimal trajectories as training\ndata, but merely needs to iteratively provide trajectories that slightly\nimprove over the trajectory currently proposed by the system. We argue that\nthis coactive preference feedback can be more easily elicited than\ndemonstrations of optimal trajectories. Nevertheless, theoretical regret bounds\nof our algorithm match the asymptotic rates of optimal trajectory algorithms.\n  We implement our algorithm on two high degree-of-freedom robots, PR2 and\nBaxter, and present three intuitive mechanisms for providing such incremental\nfeedback. In our experimental evaluation we consider two context rich settings\n-- household chores and grocery store checkout -- and show that users are able\nto train the robot with just a few feedbacks (taking only a few\nminutes).\\footnote{Parts of this work has been published at NIPS and ISRR\nconferences~\\citep{Jain13,Jain13b}. This journal submission presents a\nconsistent full paper, and also includes the proof of regret bounds, more\ndetails of the robotic system, and a thorough related work.}", "subject": "Robotics (cs.RO)"}, {"idx": 112, "title": "Service Function Chaining Simplified", "abstract": "Middleboxes have become a vital part of modern networks by providing service\nfunctions such as content filtering, load balancing and optimization of network\ntraffic. An ordered sequence of middleboxes composing a logical service is\ncalled service chain. Service Function Chaining (SFC) enables us to define\nthese service chains. Recent optimization models of SFCs assume that the\nfunctionality of a middlebox is provided by a single software appliance,\ncommonly known as Virtual Network Function (VNF). This assumption limits SFCs\nto the throughput of an individual VNF and resources of a physical machine\nhosting the VNF instance. Moreover, typical service providers offer VNFs with\nheterogeneous throughput and resource configurations. Thus, deploying a service\nchain with custom throughput can become a tedious process of stitching\nheterogeneous VNF instances. In this paper, we describe how we can overcome\nthese limitations without worrying about underlying VNF configurations and\nresource constraints. This prospect is achieved by distributed deploying\nmultiple VNF instances providing the functionality of a middlebox and modeling\nthe optimal deployment of a service chain as a mixed integer programming\nproblem. The proposed model optimizes host and bandwidth resources allocation,\nand determines the optimal placement of VNF instances, while balancing workload\nand routing traffic among these VNF instances. We show that this problem is\nNP-Hard and propose a heuristic solution called Kariz. Kariz utilizes a tuning\nparameter to control the trade-off between speed and accuracy of the solution.\nFinally, our solution is evaluated using simulations in data-center networks.", "subject": "Networking and Internet Architecture (cs.NI)"}, {"idx": 113, "title": "Translingual Obfuscation", "abstract": "Program obfuscation is an important software protection technique that\nprevents attackers from revealing the programming logic and design of the\nsoftware. We introduce translingual obfuscation, a new software obfuscation\nscheme which makes programs obscure by \"misusing\" the unique features of\ncertain programming languages. Translingual obfuscation translates part of a\nprogram from its original language to another language which has a different\nprogramming paradigm and execution model, thus increasing program complexity\nand impeding reverse engineering. In this paper, we investigate the feasibility\nand effectiveness of translingual obfuscation with Prolog, a logic programming\nlanguage. We implement translingual obfuscation in a tool called BABEL, which\ncan selectively translate C functions into Prolog predicates. By leveraging two\nimportant features of the Prolog language, i.e., unification and backtracking,\nBABEL obfuscates both the data layout and control flow of C programs, making\nthem much more difficult to reverse engineer. Our experiments show that BABEL\nprovides effective and stealthy software obfuscation, while the cost is only\nmodest compared to one of the most popular commercial obfuscators on the\nmarket. With BABEL, we verified the feasibility of translingual obfuscation,\nwhich we consider to be a promising new direction for software obfuscation.", "subject": "Cryptography and Security (cs.CR)"}, {"idx": 114, "title": "End-to-End Relation Extraction using LSTMs on Sequences and Tree Structures", "abstract": "We present a novel end-to-end neural model to extract entities and relations\nbetween them. Our recurrent neural network based model captures both word\nsequence and dependency tree substructure information by stacking bidirectional\ntree-structured LSTM-RNNs on bidirectional sequential LSTM-RNNs. This allows\nour model to jointly represent both entities and relations with shared\nparameters in a single model. We further encourage detection of entities during\ntraining and use of entity information in relation extraction via entity\npretraining and scheduled sampling. Our model improves over the\nstate-of-the-art feature-based model on end-to-end relation extraction,\nachieving 12.1% and 5.7% relative error reductions in F1-score on ACE2005 and\nACE2004, respectively. We also show that our LSTM-RNN based model compares\nfavorably to the state-of-the-art CNN based model (in F1-score) on nominal\nrelation classification (SemEval-2010 Task 8). Finally, we present an extensive\nablation analysis of several model components.", "subject": "Computation and Language (cs.CL)"}, {"idx": 115, "title": "Robust Method of Vote Aggregation and Proposition Verification for Invariant Local Features", "abstract": "This paper presents a method for analysis of the vote space created from the\nlocal features extraction process in a multi-detection system. The method is\nopposed to the classic clustering approach and gives a high level of control\nover the clusters composition for further verification steps. Proposed method\ncomprises of the graphical vote space presentation, the proposition generation,\nthe two-pass iterative vote aggregation and the cascade filters for\nverification of the propositions. Cascade filters contain all of the minor\nalgorithms needed for effective object detection verification. The new approach\ndoes not have the drawbacks of the classic clustering approaches and gives a\nsubstantial control over process of detection. Method exhibits an exceptionally\nhigh detection rate in conjunction with a low false detection chance in\ncomparison to alternative methods.", "subject": "Computer Vision and Pattern Recognition (cs.CV)"}, {"idx": 116, "title": "Experimental Study on Battery-less Sensor Network Activated by Multi-point Wireless Energy Transmission", "abstract": "This paper empirically validates battery-less sensor activation via wireless\nenergy transmission to release sensors from wires and batteries. To seamlessly\nextend the coverage and activate sensor nodes distributed in any indoor\nenvironment, we proposed multi-point wireless energy transmission with carrier\nshift diversity. In this scheme, multiple transmitters are employed to\ncompensate path-loss attenuation and orthogonal frequencies are allocated to\nthe multiple transmitters to avoid the destructive interference that occurs\nwhen the same frequency is used by all transmitters. In our previous works, the\neffectiveness of the proposed scheme was validated theoretically and also\nempirically by using just a spectrum analyzer to measure the received power. In\nthis paper, we develop low-energy battery-less sensor nodes whose consumed\npower and required received power for activation are respectively 142 uW and\n400 uW. In addition, we conduct indoor experiments in which the received power\nand activation of battery-less sensor node are simultaneously observed by using\nthe developed battery-less sensor node and a spectrum analyzer. The results\nshow that the coverage of single-point and multi-point wireless energy\ntransmission without carrier shift diversity are, respectively, 84.4% and\n83.7%, while the coverage of the proposed scheme is 100%. It can be concluded\nthat the effectiveness of the proposed scheme can be verified by our\nexperiments using real battery-less sensor nodes.", "subject": "Networking and Internet Architecture (cs.NI)"}, {"idx": 117, "title": "The Key to Intelligent Transportation: Identity and Credential Management in Vehicular Communication Systems", "abstract": "Vehicular Communication (VC) systems will greatly enhance intelligent\ntransportation systems. But their security and the protection of their users'\nprivacy are a prerequisite for deployment. Efforts in industry and academia\nbrought forth a multitude of diverse proposals. These have now converged to a\ncommon view, notably on the design of a security infrastructure, a Vehicular\nPublic Key Infrastructure (VPKI) that shall enable secure conditionally\nanonymous VC. Standardization efforts and industry readiness to adopt this\napproach hint to its maturity. However, there are several open questions\nremaining, and it is paramount to have conclusive answers before deployment. In\nthis article, we distill and critically survey the state of the art for\nidentity and credential management in VC systems, and we sketch a roadmap for\naddressing a set of critical remaining security and privacy challenges.", "subject": "Cryptography and Security (cs.CR)"}, {"idx": 118, "title": "Open challenges in understanding development and evolution of speech forms: The roles of embodied self-organization, motivation and active exploration", "abstract": "This article discusses open scientific challenges for understanding\ndevelopment and evolution of speech forms, as a commentary to Moulin-Frier et\nal. (Moulin-Frier et al., 2015). Based on the analysis of mathematical models\nof the origins of speech forms, with a focus on their assumptions , we study\nthe fundamental question of how speech can be formed out of non--speech, at\nboth developmental and evolutionary scales. In particular, we emphasize the\nimportance of embodied self-organization , as well as the role of mechanisms of\nmotivation and active curiosity-driven exploration in speech formation. Finally\n, we discuss an evolutionary-developmental perspective of the origins of\nspeech.", "subject": "Artificial Intelligence (cs.AI)"}, {"idx": 119, "title": "Gamifying Video Object Segmentation", "abstract": "Video object segmentation can be considered as one of the most challenging\ncomputer vision problems. Indeed, so far, no existing solution is able to\neffectively deal with the peculiarities of real-world videos, especially in\ncases of articulated motion and object occlusions; limitations that appear more\nevident when we compare their performance with the human one. However, manually\nsegmenting objects in videos is largely impractical as it requires a lot of\nhuman time and concentration. To address this problem, in this paper we propose\nan interactive video object segmentation method, which exploits, on one hand,\nthe capability of humans to identify correctly objects in visual scenes, and on\nthe other hand, the collective human brainpower to solve challenging tasks. In\nparticular, our method relies on a web game to collect human inputs on object\nlocations, followed by an accurate segmentation phase achieved by optimizing an\nenergy function encoding spatial and temporal constraints between object\nregions as well as human-provided input. Performance analysis carried out on\nchallenging video datasets with some users playing the game demonstrated that\nour method shows a better trade-off between annotation times and segmentation\naccuracy than interactive video annotation and automated video object\nsegmentation approaches.", "subject": "Computer Vision and Pattern Recognition (cs.CV)"}, {"idx": 120, "title": "An Analysis of Rhythmic Staccato-Vocalization Based on Frequency Demodulation for Laughter Detection in Conversational Meetings", "abstract": "Human laugh is able to convey various kinds of meanings in human\ncommunications. There exists various kinds of human laugh signal, for example:\nvocalized laugh and non vocalized laugh. Following the theories of psychology,\namong all the vocalized laugh type, rhythmic staccato-vocalization\nsignificantly evokes the positive responses in the interactions. In this paper\nwe attempt to exploit this observation to detect human laugh occurrences, i.e.,\nthe laughter, in multiparty conversations from the AMI meeting corpus. First,\nwe separate the high energy frames from speech, leaving out the low energy\nframes through power spectral density estimation. We borrow the algorithm of\nrhythm detection from the area of music analysis to use that on the high energy\nframes. Finally, we detect rhythmic laugh frames, analyzing the candidate\nrhythmic frames using statistics. This novel approach for detection of\n`positive' rhythmic human laughter performs better than the standard laughter\nclassification baseline.", "subject": "Sound (cs.SD)"}, {"idx": 121, "title": "Fast Power and Energy Efficiency Analysis of FPGA-based Wireless Base-band Processing", "abstract": "Nowadays, demands for high performance keep on increasing in the wireless\ncommunication domain. This leads to a consistent rise of the complexity and\ndesigning such systems has become a challenging task. In this context, energy\nefficiency is considered as a key topic, especially for embedded systems in\nwhich design space is often very constrained. In this paper, a fast and\naccurate power estimation approach for FPGA-based hardware systems is applied\nto a typical wireless communication system. It aims at providing power\nestimates of complete systems prior to their implementations. This is made\npossible by using a dedicated library of high-level models that are\nrepresentative of hardware IPs. Based on high-level simulations, design space\nexploration is made a lot faster and easier. The definition of a scenario and\nthe monitoring of IP's time-activities facilitate the comparison of several\ndomain-specific systems. The proposed approach and its benefits are\ndemonstrated through a typical use case in the wireless communication domain.", "subject": "Distributed, Parallel, and Cluster Computing (cs.DC)"}, {"idx": 122, "title": "Fog Networking: An Overview on Research Opportunities", "abstract": "The past 15 years have seen the rise of the Cloud, along with rapid increase\nin Internet backbone traffic and more sophisticated cellular core networks.\nThere are three different types of Clouds: (1) data center, (2) backbone IP\nnetwork and (3) cellular core network, responsible for computation, storage,\ncommunication and network management. Now the functions of these three types of\nClouds are descending to be among or near the end users, i.e., to the edge of\nnetworks, as Fog. This article presents an overview on research opportunities\nof Fog networking: an architecture that users one or a collaborative multitude\nof end-user clients or near-user edge devices to carry out a substantial amount\nof storage, communication and management. Architecture allocates\nfunctionalities, while engineering artifacts that may use a Fog architecture\ninclude 5G, home/personal networking, and the Internet of Things.", "subject": "Networking and Internet Architecture (cs.NI)"}, {"idx": 123, "title": "Approximate Distance Oracles for Planar Graphs with Improved Query Time-Space Tradeoff", "abstract": "We consider approximate distance oracles for edge-weighted n-vertex\nundirected planar graphs. Given fixed epsilon > 0, we present a\n(1+epsilon)-approximate distance oracle with O(n(loglog n)^2) space and\nO((loglog n)^3) query time. This improves the previous best product of query\ntime and space of the oracles of Thorup (FOCS 2001, J. ACM 2004) and Klein\n(SODA 2002) from O(n log n) to O(n(loglog n)^5).", "subject": "Data Structures and Algorithms (cs.DS)"}, {"idx": 124, "title": "Towards Deploying a Scalable & Robust Vehicular Identity and Credential Management Infrastructure", "abstract": "Several years of academic and industrial research efforts have converged to a\ncommon understanding on fundamental security building blocks for the upcoming\nVehicular Communication (VC) systems. There is a growing consensus towards\ndeploying a Vehicular Public-Key Infrastructure (VPKI) enables pseudonymous\nauthentication, with standardization efforts in that direction. However, there\nare still significant technical issues that remain unresolved. Existing\nproposals for instantiating the VPKI either need additional detailed\nspecifications or enhanced security and privacy features. Equally important,\nthere is limited experimental work that establishes the VPKI efficiency and\nscalability. In this paper, we are concerned with exactly these issues. We\nleverage the common VPKI approach and contribute an enhanced system with\nprecisely defined, novel features that improve its resilience and the user\nprivacy protection. In particular, we depart from the common assumption that\nthe VPKI entities are fully trusted and we improve user privacy in the face of\nan honest-but-curious security infrastructure. Moreover, we fully implement our\nVPKI, in a standard-compliant manner, and we perform an extensive evaluation.\nAlong with stronger protection and richer functionality, our system achieves\nvery significant performance improvement over prior systems - contributing the\nmost advanced VPKI towards deployment.", "subject": "Cryptography and Security (cs.CR)"}, {"idx": 125, "title": "DeFiNe: an optimisation-based method for robust disentangling of filamentous networks", "abstract": "Thread-like structures are pervasive across scales, from polymeric proteins\nto root systems to galaxy filaments, and their characteristics can be readily\ninvestigated in the network formalism. Yet, network links usually represent\nonly parts of filaments, which, when neglected, may lead to erroneous\nconclusions from network-based analyses. The existing alternatives to detect\nfilaments in network representations require tuning of parameters over a large\nrange of values and treat all filaments equally, thus, precluding automated\nanalysis of diverse filamentous systems. Here, we propose a fully automated and\nrobust optimisation-based approach to detect filaments of consistent\nintensities and angles in a given network. We test and demonstrate the accuracy\nof our solution with contrived, biological, and cosmic filamentous structures.\nIn particular, we show that the proposed approach provides powerful automated\nmeans to study properties of individual actin filaments in their network\ncontext. Our solution is made publicly available as an open-source tool,\nDeFiNe, facilitating decomposition of any given network into individual\nfilaments.", "subject": "Data Structures and Algorithms (cs.DS)"}, {"idx": 126, "title": "Self-learning and adaptation in a sensorimotor framework", "abstract": "We present a general framework to autonomously achieve a task, where autonomy\nis acquired by learning sensorimotor patterns of a robot, while it is\ninteracting with its environment. To accomplish the task, using the learned\nsensorimotor contingencies, our approach predicts a sequence of actions that\nwill lead to the desirable observations. Gaussian processes (GP) with automatic\nrelevance determination is used to learn the sensorimotor mapping. In this way,\nrelevant sensory and motor components can be systematically found in\nhigh-dimensional sensory and motor spaces. We propose an incremental GP\nlearning strategy, which discerns between situations, when an update or an\nadaptation must be implemented. RRT* is exploited to enable long-term planning\nand generating a sequence of states that lead to a given goal; while a\ngradient-based search finds the optimum action to steer to a neighbouring state\nin a single time step. Our experimental results prove the successfulness of the\nproposed framework to learn a joint space controller with high data dimensions\n(10$\\times$15). It demonstrates short training phase (less than 12 seconds),\nreal-time performance and rapid adaptations capabilities.", "subject": "Robotics (cs.RO)"}, {"idx": 127, "title": "TimeMachine: Entity-centric Search and Visualization of News Archives", "abstract": "We present a dynamic web tool that allows interactive search and\nvisualization of large news archives using an entity-centric approach. Users\nare able to search entities using keyword phrases expressing news stories or\nevents and the system retrieves the most relevant entities to the user query\nbased on automatically extracted and indexed entity profiles. From the\ncomputational journalism perspective, TimeMachine allows users to explore media\ncontent through time using automatic identification of entity names, jobs,\nquotations and relations between entities from co-occurrences networks\nextracted from the news articles. TimeMachine demo is available at\nhttp://maquinadotempo.sapo.pt/", "subject": "Information Retrieval (cs.IR)"}, {"idx": 128, "title": "Cross-layer distributed power control: A repeated games formulation to improve the sum energy-efficiency", "abstract": "The main objective of this work is to improve the energy-efficiency (EE) of a\nmultiple access channel (MAC) system, through power control, in a distributed\nmanner. In contrast with many existing works on energy-efficient power control,\nwhich ignore the possible presence of a queue at the transmitter, we consider a\nnew generalized cross-layer EE metric. This approach is relevant when the\ntransmitters have a non-zero energy cost even when the radiated power is zero\nand takes into account the presence of a finite packet buffer and packet\narrival at the transmitter. As the Nash equilibrium (NE) is an\nenergy-inefficient solution, the present work aims at overcoming this deficit\nby improving the global energy-efficiency. Indeed, as the considered system has\nmultiple agencies each with their own interest, the performance metric\nreflecting the individual interest of each decision maker is the global\nenergy-efficiency defined then as the sum over individual energy-efficiencies.\nRepeated games (RG) are investigated through the study of two dynamic games\n(finite RG and discounted RG), whose equilibrium is defined when introducing a\nnew operating point (OP), Pareto-dominating the NE and relying only on\nindividual channel state information (CSI). Accordingly, closed-form\nexpressions of the minimum number of stages of the game for finite RG (FRG) and\nthe maximum discount factor of the discounted RG (DRG) were established. The\ncross-layer model in the RG formulation leads to achieving a shorter minimum\nnumber of stages in the FRG even for higher number of users. In addition, the\nsocial welfare (sum of utilities) in the DRG decreases slightly with the\ncross-layer model when the number of users increases while it is reduced\nconsiderably with the Goodman model. Finally, we show that in real systems with\nrandom packet arrivals, the cross-layer power control algorithm outperforms the\nGoodman algorithm.", "subject": "Networking and Internet Architecture (cs.NI)"}, {"idx": 129, "title": "Proceedings of the Sixth International Workshop on Domain-Specific Languages and Models for Robotic Systems (DSLRob 2015)", "abstract": "The Sixth International Workshop on Domain-Specific Languages and Models for\nRobotic Systems (DSLRob'15) was held September 28, 2015 in Hamburg (Germany),\nas part of the IROS 2015 conference. The main topics of the workshop were\nDomain-Specific Languages (DSLs) and Model-driven Software Development (MDSD)\nfor robotics. A domain-specific language is a programming language dedicated to\na particular problem domain that offers specific notations and abstractions\nthat increase programmer productivity within that domain. Model-driven software\ndevelopment offers a high-level way for domain users to specify the\nfunctionality of their system at the right level of abstraction. DSLs and\nmodels have historically been used for programming complex systems. However\nrecently they have garnered interest as a separate field of study. Robotic\nsystems blend hardware and software in a holistic way that intrinsically raises\nmany crosscutting concerns (concurrency, uncertainty, time constraints, ...),\nfor which reason, traditional general-purpose languages often lead to a poor\nfit between the language features and the implementation requirements. DSLs and\nmodels offer a powerful, systematic way to overcome this problem, enabling the\nprogrammer to quickly and precisely implement novel software solutions to\ncomplex problems within the robotics domain.", "subject": "Robotics (cs.RO)"}, {"idx": 130, "title": "Cross validation in LASSO and its acceleration", "abstract": "We investigate leave-one-out cross validation (CV) as a determinator of the\nweight of the penalty term in the least absolute shrinkage and selection\noperator (LASSO). First, on the basis of the message passing algorithm and a\nperturbative discussion assuming that the number of observations is\nsufficiently large, we provide simple formulas for approximately assessing two\ntypes of CV errors, which enable us to significantly reduce the necessary cost\nof computation. These formulas also provide a simple connection of the CV\nerrors to the residual sums of squares between the reconstructed and the given\nmeasurements. Second, on the basis of this finding, we analytically evaluate\nthe CV errors when the design matrix is given as a simple random matrix in the\nlarge size limit by using the replica method. Finally, these results are\ncompared with those of numerical simulations on finite-size systems and are\nconfirmed to be correct. We also apply the simple formulas of the first type of\nCV error to an actual dataset of the supernovae.", "subject": "Information Theory (cs.IT)"}, {"idx": 131, "title": "The Role of Context Types and Dimensionality in Learning Word Embeddings", "abstract": "We provide the first extensive evaluation of how using different types of\ncontext to learn skip-gram word embeddings affects performance on a wide range\nof intrinsic and extrinsic NLP tasks. Our results suggest that while intrinsic\ntasks tend to exhibit a clear preference to particular types of contexts and\nhigher dimensionality, more careful tuning is required for finding the optimal\nsettings for most of the extrinsic tasks that we considered. Furthermore, for\nthese extrinsic tasks, we find that once the benefit from increasing the\nembedding dimensionality is mostly exhausted, simple concatenation of word\nembeddings, learned with different context types, can yield further performance\ngains. As an additional contribution, we propose a new variant of the skip-gram\nmodel that learns word embeddings from weighted contexts of substitute words.", "subject": "Computation and Language (cs.CL)"}, {"idx": 132, "title": "Configurable memory systems for embedded many-core processors", "abstract": "The memory system of a modern embedded processor consumes a large fraction of\ntotal system energy. We explore a range of different configuration options and\nshow that a reconfigurable design can make better use of the resources\navailable to it than any fixed implementation, and provide large improvements\nin both performance and energy consumption. Reconfigurability becomes\nincreasingly useful as resources become more constrained, so is particularly\nrelevant in the embedded space.\n  For an optimised architectural configuration, we show that a configurable\ncache system performs an average of 20% (maximum 70%) better than the best\nfixed implementation when two programs are competing for the same resources,\nand reduces cache miss rate by an average of 70% (maximum 90%). We then present\na case study of AES encryption and decryption, and find that a custom memory\nconfiguration can almost double performance, with further benefits being\nachieved by specialising the task of each core when parallelising the program.", "subject": "Hardware Architecture (cs.AR)"}, {"idx": 133, "title": "Secret Key Generation with Limited Interaction", "abstract": "A basic two-terminal secret key generation model is considered, where the\ninteractive communication rate between the terminals may be limited, and in\nparticular may not be enough to achieve the maximum key rate. We first prove a\nmulti-letter characterization of the key-communication rate region (where the\nnumber of auxiliary random variables depend on the number of rounds of the\ncommunication), and then provide an equivalent but simpler characterization in\nterms of concave envelopes in the case of unlimited number of rounds. Two\nextreme cases are given special attention. First, in the regime of very low\ncommunication rates, the \\emph{key bits per interaction bit} (KBIB) is\nexpressed with a new \"symmetric strong data processing constant\", which has a\nconcave envelope characterization analogous to that of the conventional strong\ndata processing constant. The symmetric strong data processing constant can be\nupper bounded by the supremum of the maximal correlation coefficient over a set\nof distributions, which allows us to determine the KBIB for binary symmetric\nsources, and conclude, in particular, that the interactive scheme is not more\nefficient than the one-way scheme at least in the low communication-rate\nregime. Second, a new characterization of the \\emph{minimum interaction rate\nneeded for achieving the maximum key rate} (MIMK) is given, and we resolve a\nconjecture by Tyagi regarding the MIMK for (possibly nonsymmetric) binary\nsources. We also propose a new conjecture for binary symmetric sources that the\ninteractive scheme is not more efficient than the one-way scheme at any\ncommunication rate.", "subject": "Information Theory (cs.IT)"}, {"idx": 134, "title": "Joint learning of ontology and semantic parser from text", "abstract": "Semantic parsing methods are used for capturing and representing semantic\nmeaning of text. Meaning representation capturing all the concepts in the text\nmay not always be available or may not be sufficiently complete. Ontologies\nprovide a structured and reasoning-capable way to model the content of a\ncollection of texts. In this work, we present a novel approach to joint\nlearning of ontology and semantic parser from text. The method is based on\nsemi-automatic induction of a context-free grammar from semantically annotated\ntext. The grammar parses the text into semantic trees. Both, the grammar and\nthe semantic trees are used to learn the ontology on several levels -- classes,\ninstances, taxonomic and non-taxonomic relations. The approach was evaluated on\nthe first sentences of Wikipedia pages describing people.", "subject": "Artificial Intelligence (cs.AI)"}, {"idx": 135, "title": "Assessing Mission Impact of Cyberattacks: Report of the NATO IST-128 Workshop", "abstract": "This report presents the results of a workshop conducted by the North\nAtlantic Treaty Organization (NATO) Information Systems Technology (IST) Panel\nin Istanbul, Turkey, in June 2015 to explore science and technology for\ncharacterizing the impact of cyber-attacks on missions. Military mission\nsuccess is highly dependent on the communications and information systems\n(CISs) that support the mission and their use in the cyber battlespace. The\ninexorably growing dependency on computational information processing for\nweapons, intelligence, communication, and logistics systems continues to\nincrease the vulnerability of missions to various cyber threats. Attacks on\nCISs or other cyber incidents degrade or disrupt the usage of CISs, and the\nresulting mission capability, performance, and completion. These incidents are\nexpected to increase in frequency and sophistication. The workshop participants\nconcluded that the key to solving the mission impact assessment problem was in\nadopting and developing a new model-driven paradigm that creates and validates\nmechanisms of modeling the mission organization, the mission(s), and the\ncyber-vulnerable systems that support the mission(s). Such models then simulate\nor portray the impacts of the cyber-attacks. In addition, such model-based\nanalysis could explore multiple alternative mitigation and work-around\nstrategies - an essential part of coping with mission impact - and select the\noptimal course of mitigating actions. Only such a paradigm can be expected to\nprovide meaningful, actionable information about mission impacts that have not\nbeen seen before or do not match prior experiences and patterns. The papers\npresented at this workshop are available in an accompanying volume, Proceedings\nof the NATO Workshop IST-128, Assessing Mission Impact of Cyber Attacks.", "subject": "Cryptography and Security (cs.CR)"}, {"idx": 136, "title": "DrMAD: Distilling Reverse-Mode Automatic Differentiation for Optimizing Hyperparameters of Deep Neural Networks", "abstract": "The performance of deep neural networks is well-known to be sensitive to the\nsetting of their hyperparameters. Recent advances in reverse-mode automatic\ndifferentiation allow for optimizing hyperparameters with gradients. The\nstandard way of computing these gradients involves a forward and backward pass\nof computations. However, the backward pass usually needs to consume\nunaffordable memory to store all the intermediate variables to exactly reverse\nthe forward training procedure. In this work we propose a simple but effective\nmethod, DrMAD, to distill the knowledge of the forward pass into a shortcut\npath, through which we approximately reverse the training trajectory.\nExperiments on several image benchmark datasets show that DrMAD is at least 45\ntimes faster and consumes 100 times less memory compared to state-of-the-art\nmethods for optimizing hyperparameters with minimal compromise to its\neffectiveness. To the best of our knowledge, DrMAD is the first research\nattempt to make it practical to automatically tune thousands of hyperparameters\nof deep neural networks. The code can be downloaded from\nhttps://github.com/bigaidream-projects/drmad", "subject": "Machine Learning (cs.LG)"}, {"idx": 137, "title": "Complex Decomposition of the Negative Distance kernel", "abstract": "A Support Vector Machine (SVM) has become a very popular machine learning\nmethod for text classification. One reason for this relates to the range of\nexisting kernels which allow for classifying data that is not linearly\nseparable. The linear, polynomial and RBF (Gaussian Radial Basis Function)\nkernel are commonly used and serve as a basis of comparison in our study. We\nshow how to derive the primal form of the quadratic Power Kernel (PK) -- also\ncalled the Negative Euclidean Distance Kernel (NDK) -- by means of complex\nnumbers. We exemplify the NDK in the framework of text categorization using the\nDewey Document Classification (DDC) as the target scheme. Our evaluation shows\nthat the power kernel produces F-scores that are comparable to the reference\nkernels, but is -- except for the linear kernel -- faster to compute. Finally,\nwe show how to extend the NDK-approach by including the Mahalanobis distance.", "subject": "Machine Learning (cs.LG)"}, {"idx": 138, "title": "High Frequency Remote Monitoring of Parkinson's Disease via Smartphone: Platform Overview and Medication Response Detection", "abstract": "Objective: The aim of this study is to develop a smartphone-based\nhigh-frequency remote monitoring platform, assess its feasibility for remote\nmonitoring of symptoms in Parkinson's disease, and demonstrate the value of\ndata collected using the platform by detecting dopaminergic medication\nresponse. Methods: We have developed HopkinsPD, a novel smartphone-based\nmonitoring platform, which measures symptoms actively (i.e. data are collected\nwhen a suite of tests is initiated by the individual at specific times during\nthe day), and passively (i.e. data are collected continuously in the\nbackground). After data collection, we extract features to assess measures of\nfive key behaviors related to PD symptoms -- voice, balance, gait, dexterity,\nand reaction time. A random forest classifier is used to discriminate\nmeasurements taken after a dose of medication (treatment) versus before the\nmedication dose (baseline). Results: A worldwide study for remote PD monitoring\nwas established using HopkinsPD in July, 2014. This study used entirely remote,\nonline recruitment and installation, demonstrating highly cost-effective\nscalability. In six months, 226 individuals (121 PD and 105 controls)\ncontributed over 46,000 hours of passive monitoring data and approximately\n8,000 instances of structured tests of voice, balance, gait, reaction, and\ndexterity. To the best of our knowledge, this is the first study to have\ncollected data at such a scale for remote PD monitoring. Moreover, we\ndemonstrate the initial ability to discriminate treatment from baseline with\n71.0(+-0.4)% accuracy, which suggests medication response can be monitored\nremotely via smartphone-based measures.", "subject": "Computers and Society (cs.CY)"}, {"idx": 139, "title": "Crater Detection via Convolutional Neural Networks", "abstract": "Craters are among the most studied geomorphic features in the Solar System\nbecause they yield important information about the past and present geological\nprocesses and provide information about the relative ages of observed geologic\nformations. We present a method for automatic crater detection using advanced\nmachine learning to deal with the large amount of satellite imagery collected.\nThe challenge of automatically detecting craters comes from their is complex\nsurface because their shape erodes over time to blend into the surface.\nBandeira provided a seminal dataset that embodied this challenge that is still\nan unsolved pattern recognition problem to this day. There has been work to\nsolve this challenge based on extracting shape and contrast features and then\napplying classification models on those features. The limiting factor in this\nexisting work is the use of hand crafted filters on the image such as Gabor or\nSobel filters or Haar features. These hand crafted methods rely on domain\nknowledge to construct. We would like to learn the optimal filters and features\nbased on training examples. In order to dynamically learn filters and features\nwe look to Convolutional Neural Networks (CNNs) which have shown their\ndominance in computer vision. The power of CNNs is that they can learn image\nfilters which generate features for high accuracy classification.", "subject": "Computer Vision and Pattern Recognition (cs.CV)"}, {"idx": 140, "title": "Forecasting Social Navigation in Crowded Complex Scenes", "abstract": "When humans navigate a crowed space such as a university campus or the\nsidewalks of a busy street, they follow common sense rules based on social\netiquette. In this paper, we argue that in order to enable the design of new\nalgorithms that can take fully advantage of these rules to better solve tasks\nsuch as target tracking or trajectory forecasting, we need to have access to\nbetter data in the first place. To that end, we contribute the very first large\nscale dataset (to the best of our knowledge) that collects images and videos of\nvarious types of targets (not just pedestrians, but also bikers, skateboarders,\ncars, buses, golf carts) that navigate in a real-world outdoor environment such\nas a university campus. We present an extensive evaluation where different\nmethods for trajectory forecasting are evaluated and compared. Moreover, we\npresent a new algorithm for trajectory prediction that exploits the complexity\nof our new dataset and allows to: i) incorporate inter-class interactions into\ntrajectory prediction models (e.g, pedestrian vs bike) as opposed to just\nintra-class interactions (e.g., pedestrian vs pedestrian); ii) model the degree\nto which the social forces are regulating an interaction. We call the latter\n\"social sensitivity\"and it captures the sensitivity to which a target is\nresponding to a certain interaction. An extensive experimental evaluation\ndemonstrates the effectiveness of our novel approach.", "subject": "Computer Vision and Pattern Recognition (cs.CV)"}, {"idx": 141, "title": "Weakest Precondition Reasoning for Expected Run-Times of Probabilistic Programs", "abstract": "This paper presents a wp-style calculus for obtaining bounds on the expected\nrun-time of probabilistic programs. Its application includes determining the\n(possibly infinite) expected termination time of a probabilistic program and\nproving positive almost-sure termination - does a program terminate with\nprobability one in finite expected time? We provide several proof rules for\nbounding the run-time of loops, and prove the soundness of the approach with\nrespect to a simple operational model. We show that our approach is a\nconservative extension of Nielson's approach for reasoning about the run-time\nof deterministic programs. We analyze the expected run-time of some example\nprograms including a one-dimensional random walk and the coupon collector\nproblem.", "subject": "Logic in Computer Science (cs.LO)"}, {"idx": 142, "title": "Space-Time Representation of People Based on 3D Skeletal Data: A Review", "abstract": "Spatiotemporal human representation based on 3D visual perception data is a\nrapidly growing research area. Based on the information sources, these\nrepresentations can be broadly categorized into two groups based on RGB-D\ninformation or 3D skeleton data. Recently, skeleton-based human representations\nhave been intensively studied and kept attracting an increasing attention, due\nto their robustness to variations of viewpoint, human body scale and motion\nspeed as well as the realtime, online performance. This paper presents a\ncomprehensive survey of existing space-time representations of people based on\n3D skeletal data, and provides an informative categorization and analysis of\nthese methods from the perspectives, including information modality,\nrepresentation encoding, structure and transition, and feature engineering. We\nalso provide a brief overview of skeleton acquisition devices and construction\nmethods, enlist a number of public benchmark datasets with skeleton data, and\ndiscuss potential future research directions.", "subject": "Computer Vision and Pattern Recognition (cs.CV)"}, {"idx": 143, "title": "Universal Coating for Programmable Matter", "abstract": "The idea behind universal coating is to have a thin layer of a specific\nsubstance covering an object of any shape so that one can measure a certain\ncondition (like temperature or cracks) at any spot on the surface of the object\nwithout requiring direct access to that spot. We study the universal coating\nproblem in the context of self-organizing programmable matter consisting of\nsimple computational elements, called particles, that can establish and release\nbonds and can actively move in a self-organized way. Based on that matter, we\npresent a worst-case work-optimal universal coating algorithm that uniformly\ncoats any object of arbitrary shape and size that allows a uniform coating. Our\nparticles are anonymous, do not have any global information, have constant-size\nmemory, and utilize only local interactions.", "subject": "Emerging Technologies (cs.ET)"}, {"idx": 144, "title": "A Modular Algorithm for Computing Polynomial GCDs over Number Fields presented with Multiple Extensions", "abstract": "We consider the problem of computing the monic gcd of two polynomials over a\nnumber field L = Q(alpha_1,...,alpha_n). Langemyr and McCallum have already\nshown how Brown's modular GCD algorithm for polynomials over Q can be modified\nto work for Q(alpha) and subsequently, Langemyr extended the algorithm to L[x].\nEncarnacion also showed how to use rational number to make the algorithm for\nQ(alpha) output sensitive, that is, the number of primes used depends on the\nsize of the integers in the gcd and not on bounds based on the input\npolynomials.\n  Our first contribution is an extension of Encarnacion's modular GCD algorithm\nto the case n>1, which, like Encarnacion's algorithm, is is output sensitive.\n  Our second contribution is a proof that it is not necessary to test if p\ndivides the discriminant. This simplifies the algorithm; it is correct without\nthis test.\n  Our third contribution is a modification to the algorithm to treat the case\nof reducible extensions. Such cases arise when solving systems of polynomial\nequations.\n  Our fourth contribution is an implementation of the modular GCD algorithm in\nMaple and in Magma. Both implementations use a recursive dense polynomial data\nstructure for representing polynomials over number fields with multiple field\nextensions.\n  Our fifth contribution is a primitive fraction-free algorithm. This is the\nbest non-modular approach. We present timing comparisons of the Maple and Magma\nimplementations demonstrating various optimizations and comparing them with the\nmonic Euclidan algorithm and our primitive fraction-free algorithm.", "subject": "Symbolic Computation (cs.SC)"}, {"idx": 145, "title": "Dataflow Graphs as Matrices and Programming with Higher-order Matrix Elements", "abstract": "We consider dataflow architecture for two classes of computations which admit\ntaking linear combinations of execution runs: probabilistic sampling and\ngeneralized animation. We improve the earlier technique of almost continuous\nprogram transformations by adopting a discipline of bipartite graphs linking\nnodes obtained via general transformations and nodes obtained via linear\ntransformations which makes it possible to develop and evolve dataflow programs\nover these classes of computations by continuous program transformations. The\nuse of bipartite graphs allows us to represent the dataflow programs from this\nclass as matrices of real numbers and evolve and modify programs by continuous\nchange of these numbers.\n  We develop a formalism for higher-order dataflow programming for this class\nof dataflow graphs based on the higher-order matrix elements. Some of our\nsoftware experiments are briefly discussed.", "subject": "Programming Languages (cs.PL)"}, {"idx": 146, "title": "On node models for high-dimensional road networks", "abstract": "Macroscopic traffic models are necessary for simulation and study of\ntraffic's complex macro-scale dynamics, and are often used by practitioners for\nroad network planning, integrated corridor management, and other applications.\nThese models have two parts: a link model, which describes traffic flow\nbehavior on individual roads, and a node model, which describes behavior at\nroad junctions. As the road networks under study become larger and more complex\n--- nowadays often including arterial networks --- the node model becomes more\nimportant. This paper focuses on the first order node model and has two main\ncontributions. First, we formalize the multi-commodity flow distribution at a\njunction as an optimization problem with all the necessary constraints. Most\ninteresting here is the formalization of input flow priorities. Then, we\ndiscuss a very common \"conservation of turning fractions\" or\n\"first-in-first-out\" (FIFO) constraint, and how it often produces unrealistic\nspillback. This spillback occurs when, at a diverge, a queue develops for a\nmovement that only a few lanes service, but FIFO requires that all lanes\nexperience spillback from this queue. As we show, avoiding this unrealistic\nspillback while retaining FIFO in the node model requires complicated network\ntopologies. Our second contribution is a \"partial FIFO\" mechanism that avoids\nthis unrealistic spillback, and a node model and solution algorithm that\nincorporates this mechanism. The partial FIFO mechanism is parameterized\nthrough intervals that describe how individual movements influence each other,\ncan be intuitively described from physical lane geometry and turning movement\nrules, and allows tuning to describe a link as having anything between full\nFIFO and no FIFO. Excepting the FIFO constraint, the present node model also\nfits within the well-established \"general class of first-order node models\" for\nmulti-commodity flows.", "subject": "Systems and Control (eess.SY)"}, {"idx": 147, "title": "Wikiometrics: A Wikipedia Based Ranking System", "abstract": "We present a new concept - Wikiometrics - the derivation of metrics and\nindicators from Wikipedia. Wikipedia provides an accurate representation of the\nreal world due to its size, structure, editing policy and popularity. We\ndemonstrate an innovative mining methodology, where different elements of\nWikipedia - content, structure, editorial actions and reader reviews - are used\nto rank items in a manner which is by no means inferior to rankings produced by\nexperts or other methods. We test our proposed method by applying it to two\nreal-world ranking problems: top world universities and academic journals. Our\nproposed ranking methods were compared to leading and widely accepted\nbenchmarks, and were found to be extremely correlative but with the advantage\nof the data being publically available.", "subject": "Digital Libraries (cs.DL)"}, {"idx": 148, "title": "Low-rank Matrix Factorization under General Mixture Noise Distributions", "abstract": "Many computer vision problems can be posed as learning a low-dimensional\nsubspace from high dimensional data. The low rank matrix factorization (LRMF)\nrepresents a commonly utilized subspace learning strategy. Most of the current\nLRMF techniques are constructed on the optimization problems using L1-norm and\nL2-norm losses, which mainly deal with Laplacian and Gaussian noises,\nrespectively. To make LRMF capable of adapting more complex noise, this paper\nproposes a new LRMF model by assuming noise as Mixture of Exponential Power\n(MoEP) distributions and proposes a penalized MoEP (PMoEP) model by combining\nthe penalized likelihood method with MoEP distributions. Such setting\nfacilitates the learned LRMF model capable of automatically fitting the real\nnoise through MoEP distributions. Each component in this mixture is adapted\nfrom a series of preliminary super- or sub-Gaussian candidates. Moreover, by\nfacilitating the local continuity of noise components, we embed Markov random\nfield into the PMoEP model and further propose the advanced PMoEP-MRF model. An\nExpectation Maximization (EM) algorithm and a variational EM (VEM) algorithm\nare also designed to infer the parameters involved in the proposed PMoEP and\nthe PMoEP-MRF model, respectively. The superseniority of our methods is\ndemonstrated by extensive experiments on synthetic data, face modeling,\nhyperspectral image restoration and background subtraction.", "subject": "Computer Vision and Pattern Recognition (cs.CV)"}, {"idx": 149, "title": "A Polynomial-time Algorithm to Compute Generalized Hermite Normal Form of Matrices over Z[x]", "abstract": "In this paper, a polynomial-time algorithm is given to compute the\ngeneralized Hermite normal form for a matrix F over Z[x], or equivalently, the\nreduced Groebner basis of the Z[x]-module generated by the column vectors of F.\nThe algorithm is also shown to be practically more efficient than existing\nalgorithms. The algorithm is based on three key ingredients. First, an F4 style\nalgorithm to compute the Groebner basis is adopted, where a novel prolongation\nis designed such that the coefficient matrices under consideration have\npolynomial sizes. Second, fast algorithms to compute Hermite normal forms of\nmatrices over Z are used. Third, the complexity of the algorithm are guaranteed\nby a nice estimation for the degree and height bounds of the polynomials in the\ngeneralized Hermite normal form.", "subject": "Symbolic Computation (cs.SC)"}, {"idx": 150, "title": "MAC Protocols Design for Smart Metering Network", "abstract": "The new generation of power metering system - i.e. Advanced Metering\nInfrastructure (AMI) - is expected to enable remote reading, control, demand\nresponse and other advanced functions, based on the integration of a new\ntwo-way communication network, which will be referred as Smart Metering Network\n(SMN). In this paper, we focus on the design principles of multiple access\ncontrol (MAC) protocols for SMN. First, we list several AMI applications and\nits benefits to the current power grid and user experience. Next, we introduces\nseveral features of SMN relevant to the design choice of the MAC protocols,\nincluding the SMN architecture and candidate communication technologies. After\nthat, we propose some performance evaluation metrics, such as scalability\nissue, traffic types, delay and etc, and give a survey of the associated\nresearch issues for the SMN MAC protocols design. In addition, we also note\nprogress within the new IEEE standardization task group (IEEE 802.11ah TG)\ncurrently working to create SMN standards, especially in the MAC protocols\naspect.", "subject": "Networking and Internet Architecture (cs.NI)"}, {"idx": 151, "title": "Energy Efficiency of Downlink Transmission Strategies for Cloud Radio Access Networks", "abstract": "This paper studies the energy efficiency of the cloud radio access network\n(C-RAN), specifically focusing on two fundamental and different downlink\ntransmission strategies, namely the data-sharing strategy and the compression\nstrategy. In the data-sharing strategy, the backhaul links connecting the\ncentral processor (CP) and the base-stations (BSs) are used to carry user\nmessages -- each user's messages are sent to multiple BSs; the BSs locally form\nthe beamforming vectors then cooperatively transmit the messages to the user.\nIn the compression strategy, the user messages are precoded centrally at the\nCP, which forwards a compressed version of the analog beamformed signals to the\nBSs for cooperative transmission. This paper compares the energy efficiencies\nof the two strategies by formulating an optimization problem of minimizing the\ntotal network power consumption subject to user target rate constraints, where\nthe total network power includes the BS transmission power, BS activation\npower, and load-dependent backhaul power. To tackle the discrete and nonconvex\nnature of the optimization problems, we utilize the techniques of reweighted\n$\\ell_1$ minimization and successive convex approximation to devise provably\nconvergent algorithms. Our main finding is that both the optimized data-sharing\nand compression strategies in C-RAN achieve much higher energy efficiency as\ncompared to the non-optimized coordinated multi-point transmission, but their\ncomparative effectiveness in energy saving depends on the user target rate. At\nlow user target rate, data-sharing consumes less total power than compression,\nhowever, as the user target rate increases, the backhaul power consumption for\ndata-sharing increases significantly leading to better energy efficiency of\ncompression at the high user rate regime.", "subject": "Information Theory (cs.IT)"}, {"idx": 152, "title": "Multi-Way, Multilingual Neural Machine Translation with a Shared Attention Mechanism", "abstract": "We propose multi-way, multilingual neural machine translation. The proposed\napproach enables a single neural translation model to translate between\nmultiple languages, with a number of parameters that grows only linearly with\nthe number of languages. This is made possible by having a single attention\nmechanism that is shared across all language pairs. We train the proposed\nmulti-way, multilingual model on ten language pairs from WMT'15 simultaneously\nand observe clear performance improvements over models trained on only one\nlanguage pair. In particular, we observe that the proposed model significantly\nimproves the translation quality of low-resource language pairs.", "subject": "Computation and Language (cs.CL)"}, {"idx": 153, "title": "Sparse approximation problem: how rapid simulated annealing succeeds and fails", "abstract": "Information processing techniques based on sparseness have been actively\nstudied in several disciplines. Among them, a mathematical framework to\napproximately express a given dataset by a combination of a small number of\nbasis vectors of an overcomplete basis is termed the {\\em sparse\napproximation}. In this paper, we apply simulated annealing, a metaheuristic\nalgorithm for general optimization problems, to sparse approximation in the\nsituation where the given data have a planted sparse representation and noise\nis present. The result in the noiseless case shows that our simulated annealing\nworks well in a reasonable parameter region: the planted solution is found\nfairly rapidly. This is true even in the case where a common relaxation of the\nsparse approximation problem, the $\\ell_1$-relaxation, is ineffective. On the\nother hand, when the dimensionality of the data is close to the number of\nnon-zero components, another metastable state emerges, and our algorithm fails\nto find the planted solution. This phenomenon is associated with a first-order\nphase transition. In the case of very strong noise, it is no longer meaningful\nto search for the planted solution. In this situation, our algorithm determines\na solution with close-to-minimum distortion fairly quickly.", "subject": "Information Theory (cs.IT)"}, {"idx": 154, "title": "A Note on \"Confidentiality-Preserving Image Search: A Comparative Study Between Homomorphic Encryption and Distance-Preserving Randomization\"", "abstract": "Recently, Lu et al. have proposed two image search schemes based on additive\nhomomorphic encryption [IEEE Access, 2 (2014), 125-141]. We remark that both\ntwo schemes are flawed because: (1) the first scheme does not make use of the\nadditive homomorphic property at all; (2) the additive homomorphic encryption\nin the second scheme is unnecessary and can be replaced by a more efficient\nsymmetric key encryption.", "subject": "Cryptography and Security (cs.CR)"}, {"idx": 155, "title": "Efficient tensor completion: Low-rank tensor train", "abstract": "This paper proposes a novel formulation of the tensor completion problem to\nimpute missing entries of data represented by tensors. The formulation is\nintroduced in terms of tensor train (TT) rank which can effectively capture\nglobal information of tensors thanks to its construction by a well-balanced\nmatricization scheme. Two algorithms are proposed to solve the corresponding\ntensor completion problem. The first one called simple low-rank tensor\ncompletion via tensor train (SiLRTC-TT) is intimately related to minimizing the\nTT nuclear norm. The second one is based on a multilinear matrix factorization\nmodel to approximate the TT rank of the tensor and called tensor completion by\nparallel matrix factorization via tensor train (TMac-TT). These algorithms are\napplied to complete both synthetic and real world data tensors. Simulation\nresults of synthetic data show that the proposed algorithms are efficient in\nestimating missing entries for tensors with either low Tucker rank or TT rank\nwhile Tucker-based algorithms are only comparable in the case of low Tucker\nrank tensors. When applied to recover color images represented by ninth-order\ntensors augmented from third-order ones, the proposed algorithms outperforms\nthe Tucker-based algorithms.", "subject": "Numerical Analysis (math.NA)"}, {"idx": 156, "title": "Incorporating Structural Alignment Biases into an Attentional Neural Translation Model", "abstract": "Neural encoder-decoder models of machine translation have achieved impressive\nresults, rivalling traditional translation models. However their modelling\nformulation is overly simplistic, and omits several key inductive biases built\ninto traditional models. In this paper we extend the attentional neural\ntranslation model to include structural biases from word based alignment\nmodels, including positional bias, Markov conditioning, fertility and agreement\nover translation directions. We show improvements over a baseline attentional\nmodel and standard phrase-based model over several language pairs, evaluating\non difficult languages in a low resource setting.", "subject": "Computation and Language (cs.CL)"}, {"idx": 157, "title": "Inter-tier Interference Suppression in Heterogeneous Cloud Radio Access Networks", "abstract": "Incorporating cloud computing into heterogeneous networks, the heterogeneous\ncloud radio access network (H-CRAN) has been proposed as a promising paradigm\nto enhance both spectral and energy efficiencies. Developing interference\nsuppression strategies is critical for suppressing the inter-tier interference\nbetween remote radio heads (RRHs) and a macro base station (MBS) in H-CRANs. In\nthis paper, inter-tier interference suppression techniques are considered in\nthe contexts of collaborative processing and cooperative radio resource\nallocation (CRRA). In particular, interference collaboration (IC) and\nbeamforming (BF) are proposed to suppress the inter-tier interference, and\ntheir corresponding performance is evaluated. Closed-form expressions for the\noverall outage probabilities, system capacities, and average bit error rates\nunder these two schemes are derived. Furthermore, IC and BF based CRRA\noptimization models are presented to maximize the RRH-accessed users' sum rates\nvia power allocation, which is solved with convex optimization. Simulation\nresults demonstrate that the derived expressions for these performance metrics\nfor IC and BF are accurate; and the relative performance between IC and BF\nschemes depends on system parameters, such as the number of antennas at the\nMBS, the number of RRHs, and the target signal-to-interference-plus-noise ratio\nthreshold. Furthermore, it is seen that the sum rates of IC and BF schemes\nincrease almost linearly with the transmit power threshold under the proposed\nCRRA optimization solution.", "subject": "Information Theory (cs.IT)"}, {"idx": 158, "title": "On the Scaling Exponent of Polar Codes for Binary-Input Energy-Harvesting Channels", "abstract": "This paper investigates the scaling exponent of polar codes for binary-input\nenergy-harvesting (EH) channels with infinite-capacity batteries. The EH\nprocess is characterized by a sequence of i.i.d. random variables with finite\nvariances. The scaling exponent $\u03bc$ of polar codes for a binary-input\nmemoryless channel (BMC) characterizes the closest gap between the capacity and\nnon-asymptotic rates achieved by polar codes with error probabilities no larger\nthan some non-vanishing $\\varepsilon\\in(0,1)$. It has been shown that for any\n$\\varepsilon\\in(0,1)$, the scaling exponent $\u03bc$ for any binary-input\nmemoryless symmetric channel (BMSC) with $I(q_{Y|X})\\in(0,1)$ lies between\n3.579 and 4.714 , where the upper bound $4.714$ was shown by an explicit\nconstruction of polar codes. Our main result shows that $4.714$ remains to be a\nvalid upper bound on the scaling exponent for any binary-input EH channel,\ni.e., a BMC subject to additional EH constraints. Our result thus implies that\nthe EH constraints do not worsen the rate of convergence to capacity if polar\ncodes are employed. The main result is proved by leveraging the following three\nexisting results: scaling exponent analyses for BMSCs, construction of polar\ncodes designed for binary-input memoryless asymmetric channels, and the\nsave-and-transmit strategy for EH channels.", "subject": "Information Theory (cs.IT)"}, {"idx": 159, "title": "Poisson Hole Process: Theory and Applications to Wireless Networks", "abstract": "Interference field in wireless networks is often modeled by a homogeneous\nPoisson Point Process (PPP). While it is realistic in modeling the inherent\nnode irregularity and provides meaningful first-order results, it falls short\nin modeling the effect of interference management techniques, which typically\nintroduce some form of spatial interaction among active transmitters. In some\napplications, such as cognitive radio and device-to-device networks, this\ninteraction may result in the formation of holes in an otherwise homogeneous\ninterference field. The resulting interference field can be accurately modeled\nas a Poisson Hole Process (PHP). Despite the importance of PHP in many\napplications, the exact characterization of interference experienced by a\ntypical node in a PHP is not known. In this paper, we derive several tight\nupper and lower bounds on the Laplace transform of this interference. Numerical\ncomparisons reveal that the new bounds outperform all known bounds and\napproximations, and are remarkably tight in all operational regimes of\ninterest. The key in deriving these tight and yet simple bounds is to capture\nthe local neighborhood around the typical point accurately while simplifying\nthe far field to attain tractability. Ideas for tightening these bounds further\nby incorporating the effect of overlaps in the holes are also discussed. These\nresults immediately lead to an accurate characterization of the coverage\nprobability of the typical node in a PHP under Rayleigh fading.", "subject": "Information Theory (cs.IT)"}, {"idx": 160, "title": "Attention Sensitive Web Browsing", "abstract": "With a number of cheap commercial dry EEG kits available today, it is\npossible to look at user attention driven scenarios for interaction with the\nweb browser. Using EEG to determine the user's attention level is preferable to\nusing methods such as gaze tracking or time spent on the webpage. In this paper\nwe use the attention level in three different ways. First, as a control\nmechanism, to control user interface elements such as menus or buttons. Second,\nto make the web browser responsive to the current attention level. Third, as a\nmeans for the web developer to control the user experience based on the level\nof attention paid by the user, thus creating attention sensitive websites. We\npresent implementation details for each of these, using the NeuroSky MindWave\nsensor. We also explore issues in the system, and possibility of an EEG based\nweb standard.", "subject": "Human-Computer Interaction (cs.HC)"}, {"idx": 161, "title": "Memory Matters: Convolutional Recurrent Neural Network for Scene Text Recognition", "abstract": "Text recognition in natural scene is a challenging problem due to the many\nfactors affecting text appearance. In this paper, we presents a method that\ndirectly transcribes scene text images to text without needing of sophisticated\ncharacter segmentation. We leverage recent advances of deep neural networks to\nmodel the appearance of scene text images with temporal dynamics. Specifically,\nwe integrates convolutional neural network (CNN) and recurrent neural network\n(RNN) which is motivated by observing the complementary modeling capabilities\nof the two models. The main contribution of this work is investigating how\ntemporal memory helps in an segmentation free fashion for this specific\nproblem. By using long short-term memory (LSTM) blocks as hidden units, our\nmodel can retain long-term memory compared with HMMs which only maintain\nshort-term state dependences. We conduct experiments on Street View House\nNumber dataset containing highly variable number images. The results\ndemonstrate the superiority of the proposed method over traditional HMM based\nmethods.", "subject": "Computer Vision and Pattern Recognition (cs.CV)"}, {"idx": 162, "title": "A Survey on Social Media Anomaly Detection", "abstract": "Social media anomaly detection is of critical importance to prevent malicious\nactivities such as bullying, terrorist attack planning, and fraud information\ndissemination. With the recent popularity of social media, new types of\nanomalous behaviors arise, causing concerns from various parties. While a large\namount of work have been dedicated to traditional anomaly detection problems,\nwe observe a surge of research interests in the new realm of social media\nanomaly detection. In this paper, we present a survey on existing approaches to\naddress this problem. We focus on the new type of anomalous phenomena in the\nsocial media and review the recent developed techniques to detect those special\ntypes of anomalies. We provide a general overview of the problem domain, common\nformulations, existing methodologies and potential directions. With this work,\nwe hope to call out the attention from the research community on this\nchallenging problem and open up new directions that we can contribute in the\nfuture.", "subject": "Machine Learning (cs.LG)"}, {"idx": 163, "title": "Notions of Connectivity in Overlay Networks", "abstract": "\" How well connected is the network? \" This is one of the most fundamental\nquestions one would ask when facing the challenge of designing a communication\nnetwork. Three major notions of connectivity have been considered in the\nliterature, but in the context of traditional (single-layer) networks, they\nturn out to be equivalent. This paper introduces a model for studying the three\nnotions of connectivity in multi-layer networks. Using this model, it is easy\nto demonstrate that in multi-layer networks the three notions may differ\ndramatically. Unfortunately, in contrast to the single-layer case, where the\nvalues of the three connectivity notions can be computed efficiently, it has\nbeen recently shown in the context of WDM networks (results that can be easily\ntranslated to our model) that the values of two of these notions of\nconnectivity are hard to compute or even approximate in multi-layer networks.\nThe current paper shed some positive light into the multi-layer connectivity\ntopic: we show that the value of the third connectivity notion can be computed\nin polynomial time and develop an approximation for the construction of well\nconnected overlay networks.", "subject": "Distributed, Parallel, and Cluster Computing (cs.DC)"}, {"idx": 164, "title": "Tool support for reasoning in display calculi", "abstract": "We present a tool for reasoning in and about propositional sequent calculi.\nOne aim is to support reasoning in calculi that contain a hundred rules or\nmore, so that even relatively small pen and paper derivations become tedious\nand error prone. As an example, we implement the display calculus D.EAK of\ndynamic epistemic logic. Second, we provide embeddings of the calculus in the\ntheorem prover Isabelle for formalising proofs about D.EAK. As a case study we\nshow that the solution of the muddy children puzzle is derivable for any number\nof muddy children. Third, there is a set of meta-tools, that allows us to adapt\nthe tool for a wide variety of user defined calculi.", "subject": "Logic in Computer Science (cs.LO)"}, {"idx": 165, "title": "On Measuring the Geographic Diversity of Internet Routes", "abstract": "Route diversity in networks is elemental for establishing reliable,\nhigh-capacity connections with appropriate security between endpoints. As for\nthe Internet, route diversity has already been studied at both Autonomous\nSystem- and router-level topologies by means of graph theoretical disjoint\npaths. In this paper we complement these approaches by proposing a method for\nmeasuring the diversity of Internet paths in a geographical sense. By\nleveraging the recent developments in IP geolocation we show how to map the\npaths discovered by traceroute into geographically equivalent classes. This\nallows us to identify the geographical footprints of the major transmission\npaths between end-hosts, and building on our observations, we propose a\nquantitative measure for geographical diversity of Internet routes between any\ntwo hosts.", "subject": "Networking and Internet Architecture (cs.NI)"}, {"idx": 166, "title": "Uniform-Circuit and Logarithmic-Space Approximations of Refined Combinatorial Optimization Problems", "abstract": "A significant progress has been made in the past three decades over the study\nof combinatorial NP optimization problems and their associated optimization and\napproximate classes, such as NPO, PO, APX (or APXP), and PTAS. Unfortunately, a\ncollection of problems that are simply placed inside the P-solvable\noptimization class PO never have been studiously analyzed regarding their exact\ncomputational complexity. To improve this situation, the existing framework\nbased on polynomial-time computability needs to be expanded and further refined\nfor an insightful analysis of various approximation algorithms targeting\noptimization problems within PO. In particular, we deal with those problems\ncharacterized in terms of logarithmic-space computations and uniform-circuit\ncomputations. We are focused on nondeterministic logarithmic-space (NL)\noptimization problems or NPO problems. Our study covers a wide range of\noptimization and approximation classes, dubbed as, NLO, LO, APXL, and LSAS as\nwell as new classes NC1O, APXNC1, NC1AS, and AC0O, which are founded on uniform\nfamilies of Boolean circuits. Although many NL decision problems can be\nnaturally converted into NL optimization (NLO) problems, few NLO problems have\nbeen studied vigorously. We thus provide a number of new NLO problems falling\ninto those low-complexity classes. With the help of NC1 or AC0\napproximation-preserving reductions, we also identify the most difficult\nproblems (known as complete problems) inside those classes. Finally, we\ndemonstrate a number of collapses and separations among those refined\noptimization and approximation classes with or without unproven\ncomplexity-theoretical assumptions.", "subject": "Computational Complexity (cs.CC)"}, {"idx": 167, "title": "A pragmatic approach to multi-class classification", "abstract": "We present a novel hierarchical approach to multi-class classification which\nis generic in that it can be applied to different classification models (e.g.,\nsupport vector machines, perceptrons), and makes no explicit assumptions about\nthe probabilistic structure of the problem as it is usually done in multi-class\nclassification. By adding a cascade of additional classifiers, each of which\nreceives the previous classifier's output in addition to regular input data,\nthe approach harnesses unused information that manifests itself in the form of,\ne.g., correlations between predicted classes. Using multilayer perceptrons as a\nclassification model, we demonstrate the validity of this approach by testing\nit on a complex ten-class 3D gesture recognition task.", "subject": "Machine Learning (cs.LG)"}, {"idx": 168, "title": "Streaming Gibbs Sampling for LDA Model", "abstract": "Streaming variational Bayes (SVB) is successful in learning LDA models in an\nonline manner. However previous attempts toward developing online Monte-Carlo\nmethods for LDA have little success, often by having much worse perplexity than\ntheir batch counterparts. We present a streaming Gibbs sampling (SGS) method,\nan online extension of the collapsed Gibbs sampling (CGS). Our empirical study\nshows that SGS can reach similar perplexity as CGS, much better than SVB. Our\ndistributed version of SGS, DSGS, is much more scalable than SVB mainly because\nthe updates' communication complexity is small.", "subject": "Machine Learning (cs.LG)"}, {"idx": 169, "title": "Image-based Vehicle Analysis using Deep Neural Network: A Systematic Study", "abstract": "We address the vehicle detection and classification problems using Deep\nNeural Networks (DNNs) approaches. Here we answer to questions that are\nspecific to our application including how to utilize DNN for vehicle detection,\nwhat features are useful for vehicle classification, and how to extend a model\ntrained on a limited size dataset, to the cases of extreme lighting condition.\nAnswering these questions we propose our approach that outperforms\nstate-of-the-art methods, and achieves promising results on image with extreme\nlighting conditions.", "subject": "Computer Vision and Pattern Recognition (cs.CV)"}, {"idx": 170, "title": "Distributed Binary Detection with Lossy Data Compression", "abstract": "Consider the problem where a statistician in a two-node system receives\nrate-limited information from a transmitter about marginal observations of a\nmemoryless process generated from two possible distributions. Using its own\nobservations, this receiver is required to first identify the legitimacy of its\nsender by declaring the joint distribution of the process, and then depending\non such authentication it generates the adequate reconstruction of the\nobservations satisfying an average per-letter distortion. The performance of\nthis setup is investigated through the corresponding rate-error-distortion\nregion describing the trade-off between: the communication rate, the error\nexponent induced by the detection and the distortion incurred by the source\nreconstruction. In the special case of testing against independence, where the\nalternative hypothesis implies that the sources are independent, the optimal\nrate-error-distortion region is characterized. An application example to binary\nsymmetric sources is given subsequently and the explicit expression for the\nrate-error-distortion region is provided as well. The case of \"general\nhypotheses\" is also investigated. A new achievable rate-error-distortion region\nis derived based on the use of non-asymptotic binning, improving the quality of\ncommunicated descriptions. Further improvement of performance in the general\ncase is shown to be possible when the requirement of source reconstruction is\nrelaxed, which stands in contrast to the case of general hypotheses.", "subject": "Information Theory (cs.IT)"}, {"idx": 171, "title": "A simple technique for improving multi-class classification with neural networks", "abstract": "We present a novel method to perform multi-class pattern classification with\nneural networks and test it on a challenging 3D hand gesture recognition\nproblem. Our method consists of a standard one-against-all (OAA)\nclassification, followed by another network layer classifying the resulting\nclass scores, possibly augmented by the original raw input vector. This allows\nthe network to disambiguate hard-to-separate classes as the distribution of\nclass scores carries considerable information as well, and is in fact often\nused for assessing the confidence of a decision. We show that by this approach\nwe are able to significantly boost our results, overall as well as for\nparticular difficult cases, on the hard 10-class gesture classification task.", "subject": "Machine Learning (cs.LG)"}, {"idx": 172, "title": "Rate Performance of Adaptive Link Selection in Buffer-Aided Cognitive Relay Networks", "abstract": "We investigate the performance of a two-hop cognitive relay network with a\nbuffered decode and forward (DF) relay. We derive expressions for the rate\nperformance of an adaptive link selection-based buffered relay (ALSBR) scheme\nwith peak power and peak interference constraints on the secondary nodes, and\ncompare its performance with that of conventional unbuffered relay (CUBR) and\nconventional buffered relay (CBR) schemes. Use of buffered relays with adaptive\nlink selection is shown to be particularly advantageous in underlay cognitive\nradio networks. The insights developed are of significance to system designers\nsince cognitive radio frameworks are being explored for use in 5G systems.\nComputer simulation results are presented to demonstrate accuracy of the\nderived expressions.", "subject": "Information Theory (cs.IT)"}, {"idx": 173, "title": "Optimal Power Allocation for Artificial Noise under Imperfect CSI against Spatially Random Eavesdroppers", "abstract": "In this correspondence, we study the secure multiantenna transmission with\nartificial noise (AN) under imperfect channel state information in the presence\nof spatially randomly distributed eavesdroppers. We derive the optimal\nsolutions of the power allocation between the information signal and the AN for\nminimizing the secrecy outage probability (SOP) under a target secrecy rate and\nfor maximizing the secrecy rate under a SOP constraint, respectively. Moreover,\nwe provide an interesting insight that channel estimation error affects the\noptimal power allocation strategy in opposite ways for the above two\nobjectives. When the estimation error increases, more power should be allocated\nto the information signal if we aim to decrease the rate-constrained SOP,\nwhereas more power should be allocated to the AN if we aim to increase the\nSOP-constrained secrecy rate.", "subject": "Information Theory (cs.IT)"}, {"idx": 174, "title": "LiveRank: How to Refresh Old Datasets", "abstract": "This paper considers the problem of refreshing a dataset. More precisely ,\ngiven a collection of nodes gathered at some time (Web pages, users from an\nonline social network) along with some structure (hyperlinks, social\nrelationships), we want to identify a significant fraction of the nodes that\nstill exist at present time. The liveness of an old node can be tested through\nan online query at present time. We call LiveRank a ranking of the old pages so\nthat active nodes are more likely to appear first. The quality of a LiveRank is\nmeasured by the number of queries necessary to identify a given fraction of the\nactive nodes when using the LiveRank order. We study different scenarios from a\nstatic setting where the Liv-eRank is computed before any query is made, to\ndynamic settings where the LiveRank can be updated as queries are processed.\nOur results show that building on the PageRank can lead to efficient LiveRanks,\nfor Web graphs as well as for online social networks.", "subject": "Social and Information Networks (cs.SI)"}, {"idx": 175, "title": "Part-of-Speech Tagging for Code-mixed Indian Social Media Text at ICON 2015", "abstract": "This paper discusses the experiments carried out by us at Jadavpur University\nas part of the participation in ICON 2015 task: POS Tagging for Code-mixed\nIndian Social Media Text. The tool that we have developed for the task is based\non Trigram Hidden Markov Model that utilizes information from dictionary as\nwell as some other word level features to enhance the observation probabilities\nof the known tokens as well as unknown tokens. We submitted runs for\nBengali-English, Hindi-English and Tamil-English Language pairs. Our system has\nbeen trained and tested on the datasets released for ICON 2015 shared task: POS\nTagging For Code-mixed Indian Social Media Text. In constrained mode, our\nsystem obtains average overall accuracy (averaged over all three language\npairs) of 75.60% which is very close to other participating two systems (76.79%\nfor IIITH and 75.79% for AMRITA_CEN) ranked higher than our system. In\nunconstrained mode, our system obtains average overall accuracy of 70.65% which\nis also close to the system (72.85% for AMRITA_CEN) which obtains the highest\naverage overall accuracy.", "subject": "Computation and Language (cs.CL)"}, {"idx": 176, "title": "Three-coloring triangle-free graphs on surfaces VII. A linear-time algorithm", "abstract": "We give a linear-time algorithm to decide 3-colorability of a triangle-free\ngraph embedded in a fixed surface, and a quadratic-time algorithm to output a\n3-coloring in the affirmative case. The algorithms also allow to prescribe the\ncoloring for a bounded number of vertices.", "subject": "Discrete Mathematics (cs.DM)"}, {"idx": 177, "title": "Introducing CitedReferencesExplorer (CRExplorer): A program for Reference Publication Year Spectroscopy with Cited References Standardization", "abstract": "We introduce a new tool - the CitedReferencesExplorer (CRExplorer,\nwww.crexplorer.net) - which can be used to disambiguate and analyze the cited\nreferences (CRs) of a publication set downloaded from the Web of Science (WoS).\nThe tool is especially suitable to identify those publications which have been\nfrequently cited by the researchers in a field and thereby to study for example\nthe historical roots of a research field or topic. CRExplorer simplifies the\nidentification of key publications by enabling the user to work with both a\ngraph for identifying most frequently cited reference publication years (RPYs)\nand the list of references for the RPYs which have been most frequently cited.\nA further focus of the program is on the standardization of CRs. It is a\nserious problem in bibliometrics that there are several variants of the same CR\nin the WoS. In this study, CRExplorer is used to study the CRs of all papers\npublished in the Journal of Informetrics. The analyses focus on the most\nimportant papers published between 1980 and 1990.", "subject": "Digital Libraries (cs.DL)"}, {"idx": 178, "title": "Publication boost in Web of Science journals and its effect on citation distributions", "abstract": "In this paper we show that the dramatic increase in the number of research\narticles indexed in the Web of Science database impacts the commonly observed\ndistributions of citations within these articles. First, we document that the\ngrowing number of physics articles in recent years is due to existing journals\npublishing more and more papers rather than more new journals coming into being\nas it happens in computer science. And second, even though the references from\nthe more recent papers generally cover a longer time span, the newer papers are\ncited more frequently than the older ones if the uneven paper growth is not\ncorrected for. Nevertheless, despite this change in the distribution of\ncitations, the citation behavior of scientists does not seem to have changed.", "subject": "Digital Libraries (cs.DL)"}, {"idx": 179, "title": "Automatic 3D object detection of Proteins in Fluorescent labeled microscope images with spatial statistical analysis", "abstract": "Since manual object detection is very inaccurate and time consuming, some\nautomatic object detection tools have been developed in recent years. At the\nmoment, there is no image analysis software available which provides an\nautomatic, objective assessment of 3D foci which is generally applicable.\nComplications arise from discrete foci which are very close or even come in\ncontact to other foci, moreover they are of variable sizes and show variable\nsignal-to-noise, and must be analyzed fully in 3D. Therefore we introduce the\n3D-OSCOS (3D-Object Segmentation and Colocalization Analysis based on Spatial\nstatistics) algorithm which is implemented as a user-friendly toolbox for\ninteractive detection of 3D objects and visualization of labeled images.", "subject": "Computer Vision and Pattern Recognition (cs.CV)"}, {"idx": 180, "title": "Adaptive and Efficient Nonlinear Channel Equalization for Underwater Acoustic Communication", "abstract": "We investigate underwater acoustic (UWA) channel equalization and introduce\nhierarchical and adaptive nonlinear channel equalization algorithms that are\nhighly efficient and provide significantly improved bit error rate (BER)\nperformance. Due to the high complexity of nonlinear equalizers and poor\nperformance of linear ones, to equalize highly difficult underwater acoustic\nchannels, we employ piecewise linear equalizers. However, in order to achieve\nthe performance of the best piecewise linear model, we use a tree structure to\nhierarchically partition the space of the received signal. Furthermore, the\nequalization algorithm should be completely adaptive, since due to the highly\nnon-stationary nature of the underwater medium, the optimal MSE equalizer as\nwell as the best piecewise linear equalizer changes in time. To this end, we\nintroduce an adaptive piecewise linear equalization algorithm that not only\nadapts the linear equalizer at each region but also learns the complete\nhierarchical structure with a computational complexity only polynomial in the\nnumber of nodes of the tree. Furthermore, our algorithm is constructed to\ndirectly minimize the final squared error without introducing any ad-hoc\nparameters. We demonstrate the performance of our algorithms through highly\nrealistic experiments performed on accurately simulated underwater acoustic\nchannels.", "subject": "Machine Learning (cs.LG)"}, {"idx": 181, "title": "The Impact of Project Management in Virtual Environment: A Software Industry Perspective", "abstract": "Virtual team in a project within an Organization could achieve optimize\nproject performance by acquiring appropriate human resources, coordination,\ncommunication and regular performance evaluation. According to the literature\nmany ICT tools will collaborate to manage virtual teams, but still most of the\nprojects lead to failure in the software industry. Aim of this research is to\ndiscover the most affected factors for virtual project human resource\nmanagement.", "subject": "Computers and Society (cs.CY)"}, {"idx": 182, "title": "Fractal social organization as a foundation to pervasive social computing services", "abstract": "Pervasive social computing is a promising approach that promises to empower\nboth the individual and the whole and thus candidates itself as a foundation to\nthe \"smarter\" social organizations that our new turbulent and resource-scarce\nworlds so urgently requires. In this contribution we first identify those that\nwe consider as the major requirements to be fulfilled in order to realize an\neffective pervasive social computing infrastructure. We then conjecture that\nour service-oriented community and fractal social organization fulfill those\nrequirements and therefore constitute an effective strategy to design pervasive\nsocial computing infrastructures. In order to motivate our conjecture, in this\npaper we discuss a model of social translucence and discuss fractal social\norganization as a referral service empowering a social system's parts and\nwhole.", "subject": "Computers and Society (cs.CY)"}, {"idx": 183, "title": "Some Experimental Issues in Financial Fraud Detection: An Investigation", "abstract": "Financial fraud detection is an important problem with a number of design\naspects to consider. Issues such as algorithm selection and performance\nanalysis will affect the perceived ability of proposed solutions, so for\nauditors and re-searchers to be able to sufficiently detect financial fraud it\nis necessary that these issues be thoroughly explored. In this paper we will\nrevisit the key performance metrics used for financial fraud detection with a\nfocus on credit card fraud, critiquing the prevailing ideas and offering our\nown understandings. There are many different performance metrics that have been\nemployed in prior financial fraud detection research. We will analyse several\nof the popular metrics and compare their effectiveness at measuring the ability\nof detection mechanisms. We further investigated the performance of a range of\ncomputational intelligence techniques when applied to this problem domain, and\nexplored the efficacy of several binary classification methods.", "subject": "Cryptography and Security (cs.CR)"}, {"idx": 184, "title": "A Comprehensive Formal Security Analysis of OAuth 2.0", "abstract": "The OAuth 2.0 protocol is one of the most widely deployed\nauthorization/single sign-on (SSO) protocols and also serves as the foundation\nfor the new SSO standard OpenID Connect. Despite the popularity of OAuth, so\nfar analysis efforts were mostly targeted at finding bugs in specific\nimplementations and were based on formal models which abstract from many web\nfeatures or did not provide a formal treatment at all.\n  In this paper, we carry out the first extensive formal analysis of the OAuth\n2.0 standard in an expressive web model. Our analysis aims at establishing\nstrong authorization, authentication, and session integrity guarantees, for\nwhich we provide formal definitions. In our formal analysis, all four OAuth\ngrant types (authorization code grant, implicit grant, resource owner password\ncredentials grant, and the client credentials grant) are covered. They may even\nrun simultaneously in the same and different relying parties and identity\nproviders, where malicious relying parties, identity providers, and browsers\nare considered as well. Our modeling and analysis of the OAuth 2.0 standard\nassumes that security recommendations and best practices are followed, in order\nto avoid obvious and known attacks.\n  When proving the security of OAuth in our model, we discovered four attacks\nwhich break the security of OAuth. The vulnerabilities can be exploited in\npractice and are present also in OpenID Connect.\n  We propose fixes for the identified vulnerabilities, and then, for the first\ntime, actually prove the security of OAuth in an expressive web model. In\nparticular, we show that the fixed version of OAuth (with security\nrecommendations and best practices in place) provides the authorization,\nauthentication, and session integrity properties we specify.", "subject": "Cryptography and Security (cs.CR)"}, {"idx": 185, "title": "BYOD Security: A New Business Challenge", "abstract": "Bring Your Own Device (BYOD) is a rapidly growing trend in businesses\nconcerned with information technology. BYOD presents a unique list of security\nconcerns for businesses implementing BYOD policies. Recent publications\nindicate a definite awareness of risks involved in incorporating BYOD into\nbusiness, however it is still an underrated issue compared to other IT security\nconcerns. This paper focuses on two key BYOD security issues: security\nchallenges and available frameworks. A taxonomy specifically classifying BYOD\nsecurity challenges is introduced alongside comprehensive frameworks and\nsolutions which are also analysed to gauge their limitations.", "subject": "Cryptography and Security (cs.CR)"}, {"idx": 186, "title": "Shape Animation with Combined Captured and Simulated Dynamics", "abstract": "We present a novel volumetric animation generation framework to create new\ntypes of animations from raw 3D surface or point cloud sequence of captured\nreal performances. The framework considers as input time incoherent 3D\nobservations of a moving shape, and is thus particularly suitable for the\noutput of performance capture platforms. In our system, a suitable virtual\nrepresentation of the actor is built from real captures that allows seamless\ncombination and simulation with virtual external forces and objects, in which\nthe original captured actor can be reshaped, disassembled or reassembled from\nuser-specified virtual physics. Instead of using the dominant surface-based\ngeometric representation of the capture, which is less suitable for volumetric\neffects, our pipeline exploits Centroidal Voronoi tessellation decompositions\nas unified volumetric representation of the real captured actor, which we show\ncan be used seamlessly as a building block for all processing stages, from\ncapture and tracking to virtual physic simulation. The representation makes no\nhuman specific assumption and can be used to capture and re-simulate the actor\nwith props or other moving scenery elements. We demonstrate the potential of\nthis pipeline for virtual reanimation of a real captured event with various\nunprecedented volumetric visual effects, such as volumetric distortion,\nerosion, morphing, gravity pull, or collisions.", "subject": "Graphics (cs.GR)"}, {"idx": 187, "title": "(Leftmost-Outermost) Beta Reduction is Invariant, Indeed", "abstract": "Slot and van Emde Boas' weak invariance thesis states that reasonable\nmachines can simulate each other within a polynomially overhead in time. Is\nlambda-calculus a reasonable machine? Is there a way to measure the\ncomputational complexity of a lambda-term? This paper presents the first\ncomplete positive answer to this long-standing problem. Moreover, our answer is\ncompletely machine-independent and based over a standard notion in the theory\nof lambda-calculus: the length of a leftmost-outermost derivation to normal\nform is an invariant cost model. Such a theorem cannot be proved by directly\nrelating lambda-calculus with Turing machines or random access machines,\nbecause of the size explosion problem: there are terms that in a linear number\nof steps produce an exponentially long output. The first step towards the\nsolution is to shift to a notion of evaluation for which the length and the\nsize of the output are linearly related. This is done by adopting the linear\nsubstitution calculus (LSC), a calculus of explicit substitutions modeled after\nlinear logic proof nets and admitting a decomposition of leftmost-outermost\nderivations with the desired property. Thus, the LSC is invariant with respect\nto, say, random access machines. The second step is to show that LSC is\ninvariant with respect to the lambda-calculus. The size explosion problem seems\nto imply that this is not possible: having the same notions of normal form,\nevaluation in the LSC is exponentially longer than in the lambda-calculus. We\nsolve such an impasse by introducing a new form of shared normal form and\nshared reduction, deemed useful. Useful evaluation avoids those steps that only\nunshare the output without contributing to beta-redexes, i.e. the steps that\ncause the blow-up in size. The main technical contribution of the paper is\nindeed the definition of useful reductions and the thorough analysis of their\nproperties.", "subject": "Programming Languages (cs.PL)"}, {"idx": 188, "title": "Loop Free Multipath Routing Algorithm", "abstract": "Single path routing that is currently used in the internet routers,is easy to\nimplement as it simplifies the routing tables and packet flow paths. However it\nis not optimal and has shortcomings in utilizing the network resources\noptimally, load balancing & fast recovery in case of faults (fault tolerance).\nThe given algorithm resolves all these problems by using all possible multiple\npaths for transfer of information, while retaining loop-free property. We have\nproposed a new dynamic loop-free multipath routing algorithm which improves\nnetwork throughput and network resource utilization, reduces average\ntransmission delay, and is not affected by faults in the links and router\nnodes. The main idea of this algorithm is to maintain multiple possible next\nhops for a destination along with weights. At every node, the traffic to a\ndestination is split among multiple next hops in proportion to the estimated\nweights. The number of multiple next hops also changes depending on the traffic\nconditions, but it is never less than one.", "subject": "Networking and Internet Architecture (cs.NI)"}, {"idx": 189, "title": "Hierarchical stability of nonlinear hybrid systems", "abstract": "In this short note we prove a hierarchical stability result that applies to\nhybrid dynamical systems satisfying the hybrid basic conditions of (Goebel et\nal., 2012). In particular, we establish sufficient conditions for uniform\nasymptotic stability of a compact set based on some hierarchical stability\nassumptions involving two nested closed sets containing such a compact set.\nMoreover, mimicking the well known result for cascaded systems, we prove that\nthe basin of attraction of such compact set coincides with the largest set from\nwhich all solutions are bounded. The result appears to be useful when applied\nto several recent works involving hierarchical control architectures.", "subject": "Systems and Control (eess.SY)"}, {"idx": 190, "title": "Recurrent Memory Networks for Language Modeling", "abstract": "Recurrent Neural Networks (RNN) have obtained excellent result in many\nnatural language processing (NLP) tasks. However, understanding and\ninterpreting the source of this success remains a challenge. In this paper, we\npropose Recurrent Memory Network (RMN), a novel RNN architecture, that not only\namplifies the power of RNN but also facilitates our understanding of its\ninternal functioning and allows us to discover underlying patterns in data. We\ndemonstrate the power of RMN on language modeling and sentence completion\ntasks. On language modeling, RMN outperforms Long Short-Term Memory (LSTM)\nnetwork on three large German, Italian, and English dataset. Additionally we\nperform in-depth analysis of various linguistic dimensions that RMN captures.\nOn Sentence Completion Challenge, for which it is essential to capture sentence\ncoherence, our RMN obtains 69.2% accuracy, surpassing the previous\nstate-of-the-art by a large margin.", "subject": "Computation and Language (cs.CL)"}, {"idx": 191, "title": "Encoding and Decoding Algorithms for Arbitrary Dimensional Hilbert Order", "abstract": "Hilbert order is widely applied in many areas. However, most of the\nalgorithms are confined to low dimensional cases. In this paper, algorithms for\nencoding and decoding arbitrary dimensional Hilbert order are presented. Eight\nalgorithms are proposed. Four algorithms are based on arithmetic operations and\nthe other four algorithms are based on bit operations. For the algorithms\ncomplexities, four of them are linear and the other four are constant for given\ninputs. In the end of the paper, algorithms for two dimensional Hilbert order\nare presented to demonstrate the usage of the algorithms introduced.", "subject": "Symbolic Computation (cs.SC)"}, {"idx": 192, "title": "Security and Privacy in Future Internet Architectures - Benefits and Challenges of Content Centric Networks", "abstract": "As the shortcomings of our current Internet become more and more obvious,\nresearchers have started creating alternative approaches for the Internet of\nthe future. Their design goals are mainly content-orientation, security,\nsupport for mobility and cloud computing. The probably most popular\narchitecture is called Content Centric Networking. Every communication is\ntreated as a distribution of content and caches are used within the network to\nimprove the effectiveness. While the performance gain of Content Centric\nNetworks is undoubted, there are questions about security and especially\nprivacy since it is not one of its main design principle. In this work, we\ncompare the Content Centric Networking approach with the current Internet with\nrespect to security and privacy. We analyze improvements that have been made\nand new problems that have yet to be resolved. The Internet of the future could\nbe content-oriented, so it is essential to identify potential security and\nprivacy issues that are inherent to the architecture early on.", "subject": "Cryptography and Security (cs.CR)"}, {"idx": 193, "title": "Language to Logical Form with Neural Attention", "abstract": "Semantic parsing aims at mapping natural language to machine interpretable\nmeaning representations. Traditional approaches rely on high-quality lexicons,\nmanually-built templates, and linguistic features which are either domain- or\nrepresentation-specific. In this paper we present a general method based on an\nattention-enhanced encoder-decoder model. We encode input utterances into\nvector representations, and generate their logical forms by conditioning the\noutput sequences or trees on the encoding vectors. Experimental results on four\ndatasets show that our approach performs competitively without using\nhand-engineered features and is easy to adapt across domains and meaning\nrepresentations.", "subject": "Computation and Language (cs.CL)"}, {"idx": 194, "title": "Strong Secrecy for Cooperative Broadcast Channels", "abstract": "A broadcast channel (BC) where the decoders cooperate via a one-sided link is\nconsidered. One common and two private messages are transmitted and the private\nmessage to the cooperative user should be kept secret from the\ncooperation-aided user. The secrecy level is measured in terms of strong\nsecrecy, i.e., a vanishing information leakage. An inner bound on the capacity\nregion is derived by using a channel-resolvability-based code that double-bins\nthe codebook of the secret message, and by using a likelihood encoder to choose\nthe transmitted codeword. The inner bound is shown to be tight for\nsemi-deterministic and physically degraded BCs and the results are compared to\nthose of the corresponding BCs without a secrecy constraint. Blackwell and\nGaussian BC examples illustrate the impact of secrecy on the rate regions.\nUnlike the case without secrecy, where sharing information about both private\nmessages via the cooperative link is optimal, our protocol conveys parts of the\ncommon and non-confidential messages only. This restriction reduces the\ntransmission rates more than the usual rate loss due to secrecy requirements.\nAn example that illustrates this loss is provided.", "subject": "Information Theory (cs.IT)"}, {"idx": 195, "title": "Internet of Drones", "abstract": "The Internet of Drones (IoD) is a layered network control architecture\ndesigned mainly for coordinating the access of unmanned aerial vehicles to\ncontrolled airspace, and providing navigation services between locations\nreferred to as nodes. The IoD provides generic services for various drone\napplications such as package delivery, traffic surveillance, search and rescue\nand more. In this paper, we present a conceptual model of how such an\narchitecture can be organized and we specify the features that an IoD system\nbased on our architecture should implement. For doing so, we extract key\nconcepts from three existing large scale networks, namely the air traffic\ncontrol network, the cellular network, and the Internet and explore their\nconnections to our novel architecture for drone traffic management.", "subject": "Networking and Internet Architecture (cs.NI)"}, {"idx": 196, "title": "Angrier Birds: Bayesian reinforcement learning", "abstract": "We train a reinforcement learner to play a simplified version of the game\nAngry Birds. The learner is provided with a game state in a manner similar to\nthe output that could be produced by computer vision algorithms. We improve on\nthe efficiency of regular \u03b5-greedy Q-Learning with linear function\napproximation through more systematic exploration in Randomized Least Squares\nValue Iteration (RLSVI), an algorithm that samples its policy from a posterior\ndistribution on optimal policies. With larger state-action spaces, efficient\nexploration becomes increasingly important, as evidenced by the faster learning\nin RLSVI.", "subject": "Artificial Intelligence (cs.AI)"}, {"idx": 197, "title": "Visibility Graphs, Dismantlability, and the Cops and Robbers Game", "abstract": "We study versions of cop and robber pursuit-evasion games on the visibility\ngraphs of polygons, and inside polygons with straight and curved sides. Each\nplayer has full information about the other player's location, players take\nturns, and the robber is captured when the cop arrives at the same point as the\nrobber. In visibility graphs we show the cop can always win because visibility\ngraphs are dismantlable, which is interesting as one of the few results\nrelating visibility graphs to other known graph classes. We extend this to show\nthat the cop wins games in which players move along straight line segments\ninside any polygon and, more generally, inside any simply connected planar\nregion with a reasonable boundary. Essentially, our problem is a type of\npursuit-evasion using the link metric rather than the Euclidean metric, and our\nresult provides an interesting class of infinite cop-win graphs.", "subject": "Computational Geometry (cs.CG)"}, {"idx": 198, "title": "A Serial Multilevel Hypergraph Partitioning Algorithm", "abstract": "The graph partitioning problem has many applications in scientific computing\nsuch as computer aided design, data mining, image compression and other\napplications with sparse-matrix vector multiplications as a kernel operation.\nIn many cases it is advantageous to use hypergraphs as they, compared to\ngraphs, have a more general structure and can be used to model more complex\nrelationships between groups of objects. This motivates our focus on the\nless-studied hypergraph partitioning problem.\n  In this paper, we propose a serial multi-level bipartitioning algorithm. One\nimportant step in current heuristics for hypergraph partitioning is clustering\nduring which similar vertices must be recognized. This can be particularly\ndifficult in irregular hypergraphs with high variation of vertex degree and\nhyperedge size; heuristics that rely on local vertex clustering decisions often\ngive poor partitioning quality. A novel feature of the proposed algorithm is to\nuse the techniques of rough set clustering to address this problem. We show\nthat our proposed algorithm gives on average between 18.8 per cent and 71.1 per\ncent better quality on these irregular hypergraphs by comparing it to\nstate-of-the-art hypergraph partitioning algorithms on benchmarks taken from\nreal applications.", "subject": "Data Structures and Algorithms (cs.DS)"}, {"idx": 199, "title": "Quality Adaptive Low-Rank Based JPEG Decoding with Applications", "abstract": "Small compression noises, despite being transparent to human eyes, can\nadversely affect the results of many image restoration processes, if left\nunaccounted for. Especially, compression noises are highly detrimental to\ninverse operators of high-boosting (sharpening) nature, such as deblurring and\nsuperresolution against a convolution kernel. By incorporating the non-linear\nDCT quantization mechanism into the formulation for image restoration, we\npropose a new sparsity-based convex programming approach for joint compression\nnoise removal and image restoration. Experimental results demonstrate\nsignificant performance gains of the new approach over existing image\nrestoration methods.", "subject": "Computer Vision and Pattern Recognition (cs.CV)"}]}